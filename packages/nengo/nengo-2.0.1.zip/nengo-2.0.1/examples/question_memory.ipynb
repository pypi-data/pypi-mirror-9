{
 "metadata": {
  "name": "",
  "signature": "sha256:dfee5aa0fe4431bd0979962cb2a80ead301519221130cbd64290263d5ceadf87"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Nengo example: Simple question answering with memory\n",
      "\n",
      "This demo implements a simple form of question answering. Two features (color and shape) will be bound by circular convolution and stored in a memory population. A cue will be used to determine either one of the features by deconvolution.\n",
      "\n",
      "When you run the network, it will start by binding `RED` and `CIRCLE` for 0.25 seconds and then binding `BLUE` and `SQUARE` for 0.25 seconds. Both bound semantic pointers are stored in a memory population. Then the network is asked with the cue. For example, when the cue is `CIRCLE` the network will respond with `RED`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "import nengo\n",
      "from nengo import spa"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Create the model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Number of dimensions for the Semantic Pointers\n",
      "dimensions = 32\n",
      "\n",
      "model = spa.SPA(label=\"Simple question answering\")\n",
      "\n",
      "with model:\n",
      "    model.color_in = spa.Buffer(dimensions=dimensions)\n",
      "    model.shape_in = spa.Buffer(dimensions=dimensions)\n",
      "    model.conv = spa.Memory(dimensions=dimensions, subdimensions=4, synapse=0.4)\n",
      "    model.cue = spa.Buffer(dimensions=dimensions)\n",
      "    model.out = spa.Buffer(dimensions=dimensions)\n",
      "    \n",
      "    # Connect the buffers\n",
      "    cortical_actions = spa.Actions(\n",
      "        'conv = color_in * shape_in',\n",
      "        'out = conv * ~cue'\n",
      "    )\n",
      "    model.cortical = spa.Cortical(cortical_actions)  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Provide the input\n",
      "\n",
      "The color input will `RED` and then `BLUE` for 0.25 seconds each before being turned off. In the same way the shape input will be `CIRCLE` and then `SQUARE` for 0.25 seconds each. Thus, the network will bind alternatingly `RED * CIRCLE` and `BLUE * SQUARE` for 0.5 seconds each.\n",
      "\n",
      "The cue for deconvolving bound semantic pointers will be turned off for 0.5 seconds and then cycles through `CIRCLE`, `RED`, `SQUARE`, and `BLUE` within one second. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def color_input(t):\n",
      "    if t < 0.25:\n",
      "        return 'RED'\n",
      "    elif t < 0.5:\n",
      "        return 'BLUE'\n",
      "    else:\n",
      "        return '0'\n",
      "\n",
      "def shape_input(t):\n",
      "    if t < 0.25:\n",
      "        return 'CIRCLE'\n",
      "    elif t < 0.5:\n",
      "        return 'SQUARE'\n",
      "    else:\n",
      "        return '0'\n",
      "\n",
      "def cue_input(t):\n",
      "    if t < 0.5:\n",
      "        return '0'\n",
      "    sequence = ['0', 'CIRCLE', 'RED', '0', 'SQUARE', 'BLUE']\n",
      "    idx = int(((t - 0.5) // (1. / len(sequence))) % len(sequence))\n",
      "    return sequence[idx]\n",
      "\n",
      "with model:\n",
      "    model.inp = spa.Input(color_in=color_input, shape_in=shape_input, cue=cue_input)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Probe the output"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with model:\n",
      "    model.config[nengo.Probe].synapse = nengo.Lowpass(0.03)\n",
      "    color_in = nengo.Probe(model.color_in.state.output)\n",
      "    shape_in = nengo.Probe(model.shape_in.state.output)\n",
      "    cue = nengo.Probe(model.cue.state.output)\n",
      "    conv = nengo.Probe(model.conv.state.output)\n",
      "    out = nengo.Probe(model.out.state.output)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Run the model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sim = nengo.Simulator(model)\n",
      "sim.run(3.)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Plot the results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(figsize=(10, 10))\n",
      "vocab = model.get_default_vocab(dimensions)\n",
      "\n",
      "plt.subplot(5, 1, 1)\n",
      "plt.plot(sim.trange(), model.similarity(sim.data, color_in))\n",
      "plt.legend(model.get_output_vocab('color_in').keys, fontsize='x-small')\n",
      "plt.ylabel(\"color\")\n",
      "\n",
      "plt.subplot(5, 1, 2)\n",
      "plt.plot(sim.trange(), model.similarity(sim.data, shape_in))\n",
      "plt.legend(model.get_output_vocab('shape_in').keys, fontsize='x-small')\n",
      "plt.ylabel(\"shape\")\n",
      "\n",
      "plt.subplot(5, 1, 3)\n",
      "plt.plot(sim.trange(), model.similarity(sim.data, cue))\n",
      "plt.legend(model.get_output_vocab('cue').keys, fontsize='x-small')\n",
      "plt.ylabel(\"cue\")\n",
      "\n",
      "plt.subplot(5, 1, 4)\n",
      "for pointer in ['RED * CIRCLE', 'BLUE * SQUARE']:\n",
      "    plt.plot(sim.trange(), vocab.parse(pointer).dot(sim.data[conv].T), label=pointer)\n",
      "plt.legend(fontsize='x-small')\n",
      "plt.ylabel(\"convolved\")\n",
      "\n",
      "plt.subplot(5, 1, 5)\n",
      "plt.plot(sim.trange(), spa.similarity(sim.data[out], vocab))\n",
      "plt.legend(model.get_output_vocab('out').keys, fontsize='x-small')\n",
      "plt.ylabel(\"Output\")\n",
      "plt.xlabel(\"time [s]\");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The plots of `shape`, `color`, and `convolved` show that first `RED * CIRCLE` and then `BLUE * SQUARE` will be loaded into the `convolved` buffer so after 0.5 seconds it represents the superposition `RED * CIRCLE + BLUE * SQUARE`.\n",
      "\n",
      "The last plot shows that the output is most similar to the semantic pointer bound to the current cue. For example, when `RED` and `CIRCLE` are being convolved and the cue is `CIRCLE`, the output is most similar to `RED`. Thus, it is possible to unbind semantic pointers from the superposition stored in `convolved`."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}
