<tool id="ngs_run_annotation" name="NGS Run Annotation">
  <description>Create a SAM format header from run metadata for sample annotation.</description>
  <version_command>mimodd version -q</version_command>
  <command>
  	mimodd header

	--rg-id "$rg_id"
	--rg-sm "$rg_sm"
	
	#if $str($rg_cn):
		--rg-cn "$rg_cn"
	#end if
	#if $str($rg_ds):
		--rg-ds "$rg_ds"
	#end if	
	#if $str($rg_date):
		--rg-dt "$rg_date"
	#end if
	#if $str($rg_lb):
		--rg-lb "$rg_lb"
	#end if
	#if $str($rg_pl):
		--rg-pl "$rg_pl"
	#end if
	#if $str($rg_pi):
		--rg-pi "$rg_pi"
	#end if
	#if $str($rg_pu):
		--rg-pu "$rg_pu"
	#end if
	
	--ofile "$outputfile"

  </command>

  <inputs>
    <param name="rg_id" type="text" size="80" label="read-group ID (required)">
        <sanitizer invalid_char="">
            <valid initial="string.printable">
                <remove value="&quot;" />
            </valid>
            <mapping initial="none">
                <add source="&quot;" target="\&quot;"/>
            </mapping>
        </sanitizer>
    </param>
    <param name="rg_sm" type="text" size="80" label="sample name (required)">
        <sanitizer invalid_char="">
            <valid initial="string.printable">
                <remove value="&quot;" />
            </valid>
            <mapping initial="none">
                <add source="&quot;" target="\&quot;"/>
            </mapping>
        </sanitizer>
    </param>
    <param name="rg_ds" type="text" size="80" label="description">
        <sanitizer invalid_char="">
            <valid initial="string.printable">
                <remove value="&quot;" />
            </valid>
            <mapping initial="none">
                <add source="&quot;" target="\&quot;"/>
            </mapping>
        </sanitizer>
    </param>
    <param name="rg_date" type="text" label="date (YYYY-MM-DD) the run was produced" />
    <param name="rg_cn" type="text" size="80" label="name of sequencing center">
        <sanitizer invalid_char="">
            <valid initial="string.printable">
                <remove value="&quot;" />
            </valid>
            <mapping initial="none">
                <add source="&quot;" target="\&quot;"/>
            </mapping>
        </sanitizer>
    </param>
    <param name="rg_lb" type="text" size="80" label="read-group library">
        <sanitizer invalid_char="">
            <valid initial="string.printable">
                <remove value="&quot;" />
            </valid>
            <mapping initial="none">
                <add source="&quot;" target="\&quot;"/>
            </mapping>
        </sanitizer>
    </param>
    <param name="rg_pl" type="text" label="platform/technology used to produce the reads" />
    <param name="rg_pi" type="text" label="predicted median insert size" />
    <param name="rg_pu" type="text" size="80" label="platform unit; unique identifier">
        <sanitizer invalid_char="">
            <valid initial="string.printable">
                <remove value="&quot;" />
            </valid>
            <mapping initial="none">
                <add source="&quot;" target="\&quot;"/>
            </mapping>
        </sanitizer>
    </param>
  </inputs>

  <outputs>
    <data name="outputfile" format="sam" label="${rg_sm} (${rg_id}) header information from MiModd ${tool.name} on ${on_string}"/>
  </outputs>

<help>
.. class:: infomark

   **What it does**

This tool takes the user-provided information about a next-generation sequencing run and constructs a valid header in the SAM file format from it.

The result file can be used by the tools *Convert* and *Reheader* or in the *SNAP Read Alignment* step to add run metadata to sequenced reads files (or to overwrite pre-existing information).

**Note:**

**MiModD requires run metadata for every input file at the Alignment step !**

**Tip:**

While you can do Alignments from fastq file format by providing a custom header file directly to the *SNAP Read Alignment* tool, we **recommend** you to first convert all input files to and archive all datasets in SAM/BAM format with appropriate header information prior to any downstream analysis. Although a bit more time-consuming, this practice protects against information loss and ensures that the input datasets will remain useful for others in the future.

</help>
</tool>
	
