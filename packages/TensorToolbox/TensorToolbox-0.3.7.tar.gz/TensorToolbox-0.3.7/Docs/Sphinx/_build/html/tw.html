<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Tensor Wrapper &mdash; TensorToolbox 0.3.3 documentation</title>
    
    <link rel="stylesheet" href="_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.3.3',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="TensorToolbox 0.3.3 documentation" href="index.html" />
    <link rel="up" title="Tutorial" href="tutorial.html" />
    <link rel="next" title="Tensor Train Vectors" href="ttvec.html" />
    <link rel="prev" title="Tutorial" href="tutorial.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="ttvec.html" title="Tensor Train Vectors"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="tutorial.html" title="Tutorial"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">TensorToolbox 0.3.3 documentation</a> &raquo;</li>
          <li><a href="tutorial.html" accesskey="U">Tutorial</a> &raquo;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Tensor Wrapper</a><ul>
<li><a class="reference internal" href="#construction">Construction</a></li>
<li><a class="reference internal" href="#access-and-data">Access and data</a></li>
<li><a class="reference internal" href="#views">Views</a></li>
<li><a class="reference internal" href="#grid-refinement">Grid refinement</a></li>
<li><a class="reference internal" href="#quantics-extension">Quantics extension</a></li>
<li><a class="reference internal" href="#reshape">Reshape</a></li>
<li><a class="reference internal" href="#summary-of-shapes">Summary of shapes</a></li>
<li><a class="reference internal" href="#storage">Storage</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="tutorial.html"
                        title="previous chapter">Tutorial</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="ttvec.html"
                        title="next chapter">Tensor Train Vectors</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="_sources/tw.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="tensor-wrapper">
<h1>Tensor Wrapper<a class="headerlink" href="#tensor-wrapper" title="Permalink to this headline">¶</a></h1>
<p>The tensor wrapper is a data structure which mimics the behavior of a <a class="reference external" href="http://docs.scipy.org/doc/numpy/index.html">numpy.ndarray</a> and associates each item of the tensor with the evaluation of a user-defined function on the corresponding grid point.</p>
<p>Let for example <span class="math">\(\mathcal{X} = \times_{i=1}^d {\bf x}_i\)</span>, where <span class="math">\({\bf x}_i\)</span> define the position of the grid points in the <span class="math">\(i\)</span>-th direction. Let us consider the function <span class="math">\(f:\mathcal{X}\rightarrow \mathbb{R}^{n_1\times \ldots \times n_m}\)</span>. Let us define the tensor valued tensor <span class="math">\(\mathcal{A}=f(\mathcal{X})\)</span>. Thus any entry <span class="math">\(\mathcal{A}[i_1,\ldots,i_d] = f({\bf x}_{i_1},\ldots,{\bf x}_{i_d})\)</span> is a tensor in <span class="math">\(\mathbb{R}^{n_1\times \ldots \times n_m}\)</span>. The storage of the whole tensor <span class="math">\(\mathcal{A}\)</span> can be problematic for big <span class="math">\(d\)</span> and <span class="math">\(m\)</span>, and not necessary if one is just willing to sample values from it.</p>
<p>The <tt class="xref py py-class docutils literal"><span class="pre">TensorWrapper</span></tt> allows the access to the elements of <span class="math">\(\mathcal{A}\)</span> which however are not all allocated, but computed on-the-fly and stored in a hash-table data structure (a Python dictionary). The <tt class="xref py py-class docutils literal"><span class="pre">TensorWrapper</span></tt> can be reshaped and accessed as if it was a <a class="reference external" href="http://docs.scipy.org/doc/numpy/index.html">numpy.ndarray</a> (including slicing of indices). Additionally it allows the existence of multiple views of the tensor, sharing among them the allocated data, and it allows the <em>Quantics</em> folding used within the <em>Quantics Tensor Train</em> <a class="reference internal" href="zrefs.html#khoromskij2011" id="id2">[2]</a><a class="reference internal" href="zrefs.html#khoromskij2010" id="id3">[1]</a> routines <tt class="xref py py-class docutils literal"><span class="pre">QTTvec</span></tt>.</p>
<p>In the following we will use a simple example to show the capabilities of this data structure. We will let <span class="math">\(d=2\)</span> and <span class="math">\(f:\mathcal{X}\rightarrow \mathbb{R}\)</span>.</p>
<div class="section" id="construction">
<h2>Construction<a class="headerlink" href="#construction" title="Permalink to this headline">¶</a></h2>
<p>In order to <strong>construct</strong> a <tt class="xref py py-class docutils literal"><span class="pre">TensorWrapper</span></tt> we need first to define a grid and a function.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">itertools</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">TensorToolbox</span> <span class="kn">as</span> <span class="nn">TT</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_fine</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">7</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;k&#39;</span><span class="p">:</span> <span class="mf">1.</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">params</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">params</span><span class="p">[</span><span class="s">&#39;k&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span> <span class="o">=</span> <span class="n">TT</span><span class="o">.</span><span class="n">TensorWrapper</span><span class="p">(</span> <span class="n">f</span><span class="p">,</span> <span class="p">[</span> <span class="n">x_fine</span> <span class="p">]</span><span class="o">*</span><span class="n">d</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="access-and-data">
<h2>Access and data<a class="headerlink" href="#access-and-data" title="Permalink to this headline">¶</a></h2>
<p>The <tt class="xref py py-class docutils literal"><span class="pre">TensorWrapper</span></tt> can then be <strong>accessed</strong> as a <a class="reference external" href="http://docs.scipy.org/doc/numpy/index.html">numpy.ndarray</a>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>
<span class="go">-0.33333333333333337</span>
</pre></div>
</div>
<p>This access to the <tt class="xref py py-class docutils literal"><span class="pre">TensorWrapper</span></tt> has caused the evaluation of the function <span class="math">\(f\)</span> and the storage of the associated value. In order to check the <strong>fill level</strong> of the <tt class="xref py py-class docutils literal"><span class="pre">TensorWrapper</span></tt>, we do:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">get_fill_level</span><span class="p">()</span>
<span class="go">1</span>
</pre></div>
</div>
<p>The <strong>evaluation indices</strong> at which the function has been evaluated can be retrived this way:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">get_fill_idxs</span><span class="p">()</span>
<span class="go">[(1, 2)]</span>
</pre></div>
</div>
<p>The <tt class="xref py py-class docutils literal"><span class="pre">TensorWrapper</span></tt> can be accessed using also <strong>slicing</strong> along some of the coordinates:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:</span><span class="mi">6</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span>
<span class="go">array([[-0.66666666666666674, 0.0, 0.66666666666666652],</span>
<span class="go">    [-0.66666666666666674, 0.0, 0.66666666666666652],</span>
<span class="go">    [-0.33333333333333337, 0.0, 0.66666666666666652],</span>
<span class="go">    [0.0, 0.0, 0.66666666666666652],</span>
<span class="go">    [0.33333333333333326, 0.33333333333333326, 0.66666666666666652],</span>
<span class="go">    [0.66666666666666652, 0.66666666666666652, 0.66666666666666652],</span>
<span class="go">    [1.0, 1.0, 1.0]], dtype=object)</span>
</pre></div>
</div>
<p>The <strong>data</strong> already computed are stored in the dictionary <tt class="xref py py-attr docutils literal"><span class="pre">TensorWrapper.data</span></tt>, which one can access and modify at his/her own risk. The data can be <strong>erased</strong> just by resetting the <tt class="xref py py-attr docutils literal"><span class="pre">TensorWrapper.data</span></tt> field:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="p">{}</span>
</pre></div>
</div>
<p>The constructed <tt class="xref py py-class docutils literal"><span class="pre">TensorWrapper</span></tt> to which has not been applied any of the view/extension/reshaping functions presented in the following, is called the <strong>global</strong> tensor wrapper. The shape informations regarding the global wrapper can be <em>always</em> accessed by:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">get_global_shape</span><span class="p">()</span>
<span class="go">(7, 7)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">get_global_ndim</span><span class="p">()</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">get_global_size</span><span class="p">()</span>
<span class="go">49</span>
</pre></div>
</div>
<p>If no view/extension/reshaping has been applied to the <tt class="xref py py-class docutils literal"><span class="pre">TensorWrapper</span></tt>, then the same output is obtained by:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span>
<span class="go">(7, 7)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">get_ndim</span><span class="p">()</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">get_size</span><span class="p">()</span>
<span class="go">49</span>
</pre></div>
</div>
<p>or by</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(7, 7)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">ndim</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">size</span>
<span class="go">49</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If any view/extension/reshape has been applied to the <tt class="xref py py-class docutils literal"><span class="pre">TensorWrapper</span></tt>, then the output of <tt class="xref py py-meth docutils literal"><span class="pre">TensorWrapper.get_global_shape()</span></tt> and <tt class="xref py py-meth docutils literal"><span class="pre">TensorWrapper.get_shape()</span></tt> will differ. Anyway <tt class="xref py py-meth docutils literal"><span class="pre">TensorWrapper.get_global_shape()</span></tt> will <em>always</em> return the information regarding the <strong>global</strong> tensor wrapper.</p>
</div>
</div>
<div class="section" id="views">
<h2>Views<a class="headerlink" href="#views" title="Permalink to this headline">¶</a></h2>
<p>The <tt class="xref py py-class docutils literal"><span class="pre">TensorWrapper</span></tt> allows the definition of multiple views over the defined tensor. The information regarding each view are contained in the dictionary <tt class="xref py py-attr docutils literal"><span class="pre">TensoWrapper.maps</span></tt>. The main view is called <tt class="docutils literal"><span class="pre">full</span></tt> and is defined at construction time. Additional views can be defined through the function <tt class="xref py py-meth docutils literal"><span class="pre">TensorWrapper.set_view()</span></tt>. Let&#8217;s continue the previous example, by adding a new view to the wrapper with a coarser grid.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">x_coarse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">set_view</span><span class="p">(</span> <span class="s">&#39;coarse&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">x_coarse</span><span class="p">]</span><span class="o">*</span><span class="n">d</span> <span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The grid of the <tt class="docutils literal"><span class="pre">full</span></tt> view must contain the grids associated to the new view.</p>
</div>
<p>The different views can be accessed separately, but they all refer to the same global data structure. In order to access the <tt class="xref py py-class docutils literal"><span class="pre">TensorWrapper</span></tt> through one of its views, the view must be <strong>activated</strong>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">set_active_view</span><span class="p">(</span><span class="s">&#39;coarse&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="p">[</span><span class="mi">2</span><span class="p">,:]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">set_active_view</span><span class="p">(</span><span class="s">&#39;full&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="p">[</span><span class="mi">1</span><span class="p">,:]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="p">[:,</span><span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
<p>The following figure shows the global grid as well as its two views, the <tt class="docutils literal"><span class="pre">full</span></tt> and the <tt class="docutils literal"><span class="pre">coarse</span></tt> views. The allocated indicies are also highlighted.</p>
<div class="figure">
<img alt="_images/TensorWrapperViews.png" src="_images/TensorWrapperViews.png" />
<p class="caption">The global tensor and two of its views. The <tt class="docutils literal"><span class="pre">full</span></tt> view corresponds by default to the global tensor. The <tt class="docutils literal"><span class="pre">coarse</span></tt> is contained in the <tt class="docutils literal"><span class="pre">full</span></tt> view. The uniquely allocated values of the tensor are shown in the different views.</p>
</div>
<p>The shape characteristics of the active view can be accessed through <tt class="xref py py-meth docutils literal"><span class="pre">TensorWrapper.get_view_shape()</span></tt> and the corresponding commands for <tt class="docutils literal"><span class="pre">ndim</span></tt> and <tt class="docutils literal"><span class="pre">size</span></tt>. For example:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">set_active_view</span><span class="p">(</span><span class="s">&#39;full&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">get_view_shape</span><span class="p">()</span>
<span class="go">(7, 7)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span>
<span class="go">(7, 7)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">set_active_view</span><span class="p">(</span><span class="s">&#39;coarse&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">get_global_shape</span><span class="p">()</span>
<span class="go">(7, 7)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">get_view_shape</span><span class="p">()</span>
<span class="go">(4, 4)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span>
<span class="go">(4, 4)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(4, 4)</span>
</pre></div>
</div>
</div>
<div class="section" id="grid-refinement">
<h2>Grid refinement<a class="headerlink" href="#grid-refinement" title="Permalink to this headline">¶</a></h2>
<p>The <em>global</em> grid can be refined using the function <tt class="xref py py-meth docutils literal"><span class="pre">TensorWrapper.refine()</span></tt>, provinding a grid which contains the previous one. This refinement does not alter the allocated data which is instead preserved and mapped to the new mesh.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">x_ffine</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">13</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">refine</span><span class="p">([</span><span class="n">x_ffine</span><span class="p">]</span><span class="o">*</span><span class="n">d</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure">
<img alt="_images/TensorWrapperRefine.png" src="_images/TensorWrapperRefine.png" />
<p class="caption">The global tensor and the two views defined, after the grid refinement.</p>
</div>
</div>
<div class="section" id="quantics-extension">
<h2>Quantics extension<a class="headerlink" href="#quantics-extension" title="Permalink to this headline">¶</a></h2>
<p>The quantics extension is used for extending the indices of the tesnor to the next power of <tt class="docutils literal"><span class="pre">Q</span></tt>. The extension is performed so that the last coordinate point is appended to the coordinate points the necessary number of times. In order to apply the extension on a particular view, one needs to activate the view and then use the method <tt class="xref py py-meth docutils literal"><span class="pre">TensorWrapper.set_Q()</span></tt>.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">set_active_view</span><span class="p">(</span><span class="s">&#39;full&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">get_view_shape</span><span class="p">()</span>
<span class="go">(13, 13)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">get_extended_shape</span><span class="p">()</span>
<span class="go">(13, 13)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">set_Q</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">get_extended_shape</span><span class="p">()</span>
<span class="go">(16, 16)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span>
<span class="go">(16, 16)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(16, 16)</span>
</pre></div>
</div>
<p>We can see that <tt class="xref py py-meth docutils literal"><span class="pre">TensorWrapper.get_extended_shape()</span></tt> returns the same output of <tt class="xref py py-meth docutils literal"><span class="pre">TensorWrapper.get_viw_shape()</span></tt> if no quantics extension has been applied.</p>
<p>Using the following code we can investigate the content of the extended tensor wrapper and plot it as shown in the following figure.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">TW</span><span class="p">[:,:]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">interpolation</span><span class="o">=</span><span class="s">&#39;none&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure">
<img alt="_images/TensorWrapperQExtension.png" src="_images/TensorWrapperQExtension.png" />
<p class="caption">The <em>Quantics</em> extension applied to the <tt class="docutils literal"><span class="pre">full</span></tt> view results in the repetition of its limit values in the tensor grid.</p>
</div>
</div>
<div class="section" id="reshape">
<h2>Reshape<a class="headerlink" href="#reshape" title="Permalink to this headline">¶</a></h2>
<p>The shape of each view can be changed as long as the size returned by <tt class="xref py py-meth docutils literal"><span class="pre">TensorWrapper.get_extended_size()</span></tt> is unchanged. This means that if <em>no quantics</em> extension has been applied, the size must correspond to <tt class="xref py py-meth docutils literal"><span class="pre">TensorWrapper.get_view_size()</span></tt>. If a <em>quantics</em> extension has been applied, the size must correspond to <tt class="xref py py-meth docutils literal"><span class="pre">TensorWrapper.get_extended_size()</span></tt>.</p>
<p>For example let us reshape the <em>quantics</em> extended <tt class="docutils literal"><span class="pre">full</span></tt> view of the tensor to the shape (4,16).</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">set_active_view</span><span class="p">(</span><span class="s">&#39;full&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">8</span><span class="p">,</span><span class="mi">32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">get_extended_shape</span><span class="p">()</span>
<span class="go">(16, 16)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span>
<span class="go">(8, 32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(8, 32)</span>
</pre></div>
</div>
<p>This results in the following reshaping of the tensor view:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">TW</span><span class="p">[:,:]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">interpolation</span><span class="o">=</span><span class="s">&#39;none&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure">
<img alt="_images/TensorWrapperReshape.png" src="_images/TensorWrapperReshape.png" />
<p class="caption">Reshaping of the <em>quantics</em> extended <tt class="docutils literal"><span class="pre">full</span></tt> view.</p>
</div>
<p>The <em>quantics</em> extension is used mainly to obtain a complete folding of base <tt class="docutils literal"><span class="pre">Q</span></tt>. In this case this is obtained by:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">math</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="nb">int</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">TW</span><span class="o">.</span><span class="n">size</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span> <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">get_extended_shape</span><span class="p">()</span>
<span class="go">(16, 16)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span>
<span class="go">(2, 2, 2, 2, 2, 2, 2, 2)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(2, 2, 2, 2, 2, 2, 2, 2)</span>
</pre></div>
</div>
<p>We finally can reset the shape to the <em>view</em> shape using:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">reset_shape</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="summary-of-shapes">
<h2>Summary of shapes<a class="headerlink" href="#summary-of-shapes" title="Permalink to this headline">¶</a></h2>
<p>Information regarding several shape transformations are always hold in the data structure. A hierarchy of shapes is used. The top shape is the <strong>global</strong> shape. In the following table we list the different shapes, their description and the main functions related and affecting them.</p>
<table border="1" class="docutils">
<colgroup>
<col width="5%" />
<col width="46%" />
<col width="50%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><strong>Shape</strong></td>
<td><strong>Description</strong></td>
<td><strong>Functions</strong></td>
</tr>
<tr class="row-even"><td>Global</td>
<td>This is the underlying shape of the <tt class="xref py py-class docutils literal"><span class="pre">TensorWrapper</span></tt>.</td>
<td><tt class="xref py py-meth docutils literal"><span class="pre">get_global_shape()</span></tt>, <tt class="xref py py-meth docutils literal"><span class="pre">get_global_ndim()</span></tt>, <tt class="xref py py-meth docutils literal"><span class="pre">get_global_size()</span></tt>, <tt class="xref py py-meth docutils literal"><span class="pre">refine()</span></tt></td>
</tr>
<tr class="row-odd"><td>View</td>
<td>Multiple views can be defined for a <tt class="xref py py-class docutils literal"><span class="pre">TensorWrapper</span></tt>. The views are defined as nested grids into the global grid. The default view is called <tt class="docutils literal"><span class="pre">full</span></tt> and is defined automatically at construction time</td>
<td><tt class="xref py py-meth docutils literal"><span class="pre">set_view()</span></tt>, <tt class="xref py py-meth docutils literal"><span class="pre">set_active_view()</span></tt>, <tt class="xref py py-meth docutils literal"><span class="pre">get_view_shape()</span></tt>, <tt class="xref py py-meth docutils literal"><span class="pre">get_view_ndim()</span></tt>, <tt class="xref py py-meth docutils literal"><span class="pre">get_view_size()</span></tt>, <tt class="xref py py-meth docutils literal"><span class="pre">refine()</span></tt></td>
</tr>
<tr class="row-even"><td>Quantics Extended</td>
<td>Each view can be extended to the next power of <tt class="docutils literal"><span class="pre">Q</span></tt> in order to allow the <em>quantics</em> folding <a class="reference internal" href="zrefs.html#khoromskij2011" id="id5">[2]</a><a class="reference internal" href="zrefs.html#khoromskij2010" id="id6">[1]</a> of the tensor.</td>
<td><tt class="xref py py-meth docutils literal"><span class="pre">set_Q()</span></tt>, <tt class="xref py py-meth docutils literal"><span class="pre">get_extended_shape()</span></tt>, <tt class="xref py py-meth docutils literal"><span class="pre">get_extended_ndim()</span></tt>, <tt class="xref py py-meth docutils literal"><span class="pre">get_extended_size()</span></tt></td>
</tr>
<tr class="row-odd"><td>Reshape</td>
<td>This is the result of the reshape of the tensor. If any of the preceding shape transformations have been applied, then the reshape is applied to the lowest transformation.</td>
<td><tt class="xref py py-meth docutils literal"><span class="pre">reshape()</span></tt>, <tt class="xref py py-meth docutils literal"><span class="pre">get_shape()</span></tt>, <tt class="xref py py-meth docutils literal"><span class="pre">get_ndim()</span></tt>, <tt class="xref py py-meth docutils literal"><span class="pre">get_size()</span></tt>, <tt class="xref py py-attr docutils literal"><span class="pre">shape</span></tt>, <tt class="xref py py-attr docutils literal"><span class="pre">ndim</span></tt>, <tt class="xref py py-attr docutils literal"><span class="pre">size</span></tt></td>
</tr>
</tbody>
</table>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">If a shape at any level is modified, every lower reshaping is automatically erased, due to possible inconsistency. For example, if a view is modified, any quantics extension and/or reshape of the view are reset.</p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The <tt class="xref py py-meth docutils literal"><span class="pre">refine()</span></tt> function erases all the quantics extensions and the reshapes of each view, but not the views themselves. Instead for each view, the <tt class="xref py py-meth docutils literal"><span class="pre">refine()</span></tt> function updates the corresponding indices, fitting the old views to the new refinement.</p>
</div>
</div>
<div class="section" id="storage">
<h2>Storage<a class="headerlink" href="#storage" title="Permalink to this headline">¶</a></h2>
<p>Instances of the class <tt class="xref py py-class docutils literal"><span class="pre">TensorWrapper</span></tt> can be stored in files and reloaded as needed. The class <tt class="xref py py-class docutils literal"><span class="pre">TensorWrapper</span></tt> extends the class <tt class="xref py py-class docutils literal"><span class="pre">storable_object</span></tt>, which is responsible for storing objects in the <a class="reference internal" href="api-wttvec.html#module-TensorToolbox" title="TensorToolbox"><tt class="xref py py-mod docutils literal"><span class="pre">TensorToolbox</span></tt></a>.</p>
<p>For the sake of efficiency and readability of the code, the <tt class="xref py py-class docutils literal"><span class="pre">TensorWrapper</span></tt> is stored in two different files with a common file name <tt class="docutils literal"><span class="pre">filename</span></tt>:</p>
<ul class="simple">
<li><tt class="docutils literal"><span class="pre">filename.pkl</span></tt> is a serialized version of the object thorugh the <a class="reference external" href="https://docs.python.org/2/library/pickle.html">pickle</a> library. The <tt class="xref py py-class docutils literal"><span class="pre">TensorWrapper</span></tt> serializes a minimal amount of auxiliary information needed for the definition of shapes, meshes, etc. The allocated data are not serialized using pickle, because when the amount of data is big, this would result in a very slow storage.</li>
<li><tt class="docutils literal"><span class="pre">filename.h5</span></tt> is a binary file containing the allocated data of the <tt class="xref py py-class docutils literal"><span class="pre">TensorWrapper</span></tt>. This file is generated using <a class="reference external" href="http://www.h5py.org/">h5py</a> and results in fast loading, writing and appending of data.</li>
</ul>
<p>Let us store the <tt class="xref py py-class docutils literal"><span class="pre">TensorWrapper</span></tt>, we have been using up to now.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">set_store_location</span><span class="p">(</span><span class="s">&#39;tensorwrapper&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">store</span><span class="p">(</span><span class="n">force</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
<p>Check that the files have been stored:</p>
<div class="highlight-bash"><div class="highlight"><pre><span class="nv">$ </span>ls
tensorwrapper.h5  tensorwrapper.pkl  WrapperExample.py
</pre></div>
</div>
<p>Let&#8217;s now reload the <tt class="xref py py-class docutils literal"><span class="pre">TensorWrapper</span></tt>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span> <span class="o">=</span> <span class="n">TT</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s">&#39;tensorwrapper&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>The storage of the tensor wrapper can also be triggered using a timer. This is mostly useful when many time consuming computations need to be performed in order to allocate the desired entries of the tensor, and one wants to have always a backup copy of the data. The trigger for the storage is checked any time a new entry needs to be allocated fo storage.</p>
<p>For example, we can set the storage frequency to 5s:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">time</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="p">{}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="o">.</span><span class="n">set_store_freq</span><span class="p">(</span> <span class="mi">5</span> <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">6.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">TW</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
<p>Checking the output we see:</p>
<div class="highlight-bash"><div class="highlight"><pre><span class="nv">$ </span>ls
tensorwrapper.h5      tensorwrapper.pkl     WrapperExample.py
tensorwrapper.h5.old  tensorwrapper.pkl.old
</pre></div>
</div>
<p>where the files <tt class="docutils literal"><span class="pre">.pkl</span></tt> and <tt class="docutils literal"><span class="pre">.h5</span></tt> are the files stored when the time-trigger is activated, while the files <tt class="docutils literal"><span class="pre">.pkl.old</span></tt> and <tt class="docutils literal"><span class="pre">h5.old</span></tt> are backup files containing the data stored in the previous example.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="ttvec.html" title="Tensor Train Vectors"
             >next</a> |</li>
        <li class="right" >
          <a href="tutorial.html" title="Tutorial"
             >previous</a> |</li>
        <li><a href="index.html">TensorToolbox 0.3.3 documentation</a> &raquo;</li>
          <li><a href="tutorial.html" >Tutorial</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2013-2015, Daniele Bigoni.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.3.
    </div>
  </body>
</html>