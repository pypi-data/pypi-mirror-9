[transmogrifier]
pipeline =
# Initialize the pipeline from a directory
    dirwalker

# Process any .htaccess files for redirects or .htpasswd files
    htaccess-filename
    htaccess-directives
    keep-directives
    redirect-directive-path

# Import users roles from Apache .htpasswd files
    htpasswd-filename
    htpasswd-users
    encrypted
    roles
    domains
    groups
    addUser
    local-roles

# Set the URL and filter
    url
    drop-seen-urls
    drop-matching

# Beginning of the crawling/spidering recursion
    deferred
    crawled
    breaker

# Update content link elements before dropping
#   after original item's redirects have been added
#   but before original item's 'text' is generated
    update-content-elements
    keep-seen-nav

# Extract content data from parents
    parent-path-from-parent
    delete-parent

# Open URL or use cache or fall back to a local filesystem
    urlopen
    localopen

# Handle redirect responses
    redirected-url
    is-external
    remoteUrl
    redirect-old-path
    url-redirect-path
    redirect-cleanup

# Extract content information from response and parsed XML
    parse
    empty-tree
    absolute-links
    title
    title-from-id
    id
    description
    subject
    modificationDate
    content
    html-file

# Assemble the path and type
    type
    parent-path-from-path
    path
    drop-seen-paths
    seen
    context
    resolve-context
    unique

# Parse XML trees for heirarchy/structure and for links to crawl/spider
    walk-content

    relatedItems-tree
    walk-relatedItems
    relatedItems

    left-nav
    walk-left-nav

    nav
    walk-nav

    delete-trees
    
# Send newly crawled/spidered links back to the top, recurse
    drop-matching
    log-dropped
    drop
    log-crawled
    crawl

# Add the content
#    blob
    folders
    content-redirect-path
    update-redirects
    container
    container-redirect
    context
    resolve-context
    excludeFromNav
    debug
    drop-construct
    log-content
    disable_versioning
    add-redirects
    construct
    enable_versioning

# Defer some keys that need redirector entries from other content
    log-deferred
    defer-links
    update-redirects
    context
    resolve
    text
    delete-content
    file

# Update the content
    set-local-roles

    update
    close

    transitions
    publish

    defaultpage
    browserdefault

    reindexobject

# Free memory in batches of transactions
    savepoint


## Initialize the pipeline with a URL to crawl

[dirwalker]
# Start the pipeline with at least a root directory,
#   optionally follow with a directory structure
blueprint = collective.transmogrifier.sections.dirwalker
dirname = plone.app.transmogrifier:empty-site
path-key = _old_paths


# Process any .htaccess files for redirects or .htpasswd files

[htaccess-filename]
blueprint = collective.transmogrifier.sections.inserter
key = string:_htaccess-directives
condition = python:modules['posixpath'].basename(
    item.get('_old_paths', '')) == '.htaccess'
value = python:${localopen:value-python}

[htaccess-directives]
blueprint = collective.transmogrifier.sections.csvsource
fieldnames = _directive
fmtparam-delimiter =  python:' '
restkey = _args
row-key = ${htpasswd-filename:condition} and '_htpasswd_path'
row-value = python:modules['posixpath'].dirname(
    filename)[len(transmogrifier['dirwalker']['dirname']):
    ] + modules['posixpath'].sep


[keep-directives]
blueprint = collective.transmogrifier.sections.condition
condition = python:'_directive' not in item or (
    item.get('_directive', '').lower() in ('redirect', 'authuserfile'))

[redirect-directive-path]
blueprint = collective.transmogrifier.sections.inserter
condition = python:item.get('_directive', '').lower() == 'redirect'
key = string:_old_paths
value = python:modules['urllib'].unquote(item['_args'][1])

[htpasswd-filename]
blueprint = collective.transmogrifier.sections.inserter
condition = python:item.get('_directive', '').lower() == 'authuserfile'
key = string:_htpasswd-users
value = python:item['_args'][0]



## Import users from Apache users

[htpasswd-users]
blueprint = collective.transmogrifier.sections.csvsource
fmtparam-delimiter = string::
fieldnames = _login _password
row-key = string:_path
row-value = source_item/_htpasswd_path

[encrypted]
blueprint = collective.transmogrifier.sections.inserter
key = string:_password
condition = exists:item/_password
prefix = {CRYPT}
value = string:${options/prefix}${item/_password}

[roles]
blueprint = collective.transmogrifier.sections.inserter
key = string:_roles
condition = exists:item/_login
value = python:['Member']

[domains]
blueprint = collective.transmogrifier.sections.inserter
key = string:_domains
condition = exists:item/_login
value = python:[]

[groups]
blueprint = collective.transmogrifier.sections.inserter
key = string:_groups
condition = exists:item/_login
value = python:[]

[addUser]
blueprint = collective.transmogrifier.sections.inserter
key = nothing
condition = python:('_login' in item and '_password' in item and
    transmogrifier.context.acl_users._doAddUser(**dict(
        (key[1:], value) for key, value in item.iteritems()
        if key.startswith('_'))) and False)
value = nothing

[local-roles]
blueprint = collective.transmogrifier.sections.inserter
roles = Reader
key = string:_local_roles
# Don't set local roles for the root
condition = python:'_login' in item and item.get('_path') not in ('', '/')
value = python:options['roles'].splitlines()


[url]
# Set the URL to crawl, relative to the url option
blueprint = collective.transmogrifier.sections.inserter
key = string:_url
condition = python:'_url' not in item and '_old_paths' in item 
# Set the `netloc` option to define the root URL to crawl
#netloc = foo.com
# You may optionally override the scheme or path
#   to further specify the root URL
scheme = http
path = /
root = ${url:scheme}://${url:netloc}${url:path}
value = python:modules['urlparse'].urlsplit(modules['urlparse'].urljoin(
      options['root'], modules['urllib'].quote(item['_old_paths'])))

[drop-seen-urls]
# Don't process walked directories for URLs that were walked from nav
blueprint = collective.transmogrifier.sections.condition
condition = python:('_url' not in item or
    item['_url'].geturl().rstrip('/') not in
    transmogrifier.__annotations__.get('xmlwalker.paths', {}))


## Central crawling loop
#    This is the source for items deferred until redirections are processed
[deferred]
blueprint = collective.transmogrifier.sections.listsource
#    This is the source for items from links that are crawled
[crawled]
# Emit crawled items before deferred ones
blueprint = collective.transmogrifier.sections.listsource

[update-content-elements]
blueprint = plone.app.transmogrifier.redirector
path-key =
update-path-keys = _content_element

[keep-seen-nav]
# Only process paths for seen URLs when they're from nav
blueprint = collective.transmogrifier.sections.condition
condition = python:('_url' not in item
    or item['_url'].geturl().rstrip('/') not in
    transmogrifier.__annotations__.get('xmlwalker.paths', {})
    or not item.get('excludeFromNav', True))


## Extract content data from parents
# Any parent information that depends on the parent crawling response
# and is needed by it's children, such as paths, must be extracted
# after the walked items to be crawled get sent back to the list
# source because the crawled items must be exhausted before the list
# source will emit the parents

[parent-path-from-parent]
blueprint = collective.transmogrifier.sections.inserter
key = string:_parent_path
condition = python:'_parent_path' not in item and '_parent' in item
value = python:(item['_parent'].get('_type') == 'Folder'
    and item['_parent'].get('_path', item['_parent'].get(
        '_plone.app.transmogrifier.redirector_path'))) or item['_parent'].get(
    '_parent_path', modules['posixpath'].dirname(item['_parent'].get(
        '_path', item['_parent'].get(
            '_plone.app.transmogrifier.redirector_path'))))

[parent-path-from-path]
blueprint = collective.transmogrifier.sections.inserter
key = string:_parent_path
condition = python:'_parent_path' not in item and '_old_paths' in item
value = python:modules['posixpath'].dirname(item['_old_paths'].rstrip('/'))

# Free reference to parent
[delete-parent]
blueprint = collective.transmogrifier.sections.manipulator
condition = exists:item/_parent
delete = _parent


# Extract content information from response and parsed XML

[urlopen]
blueprint = collective.transmogrifier.sections.urlopener
auth-codes =
    UNAUTHORIZED
    PAYMENT_REQUIRED
    PROXY_AUTHENTICATION_REQUIRED
auth-codes-python = getattr(modules['httplib'], status) for status in
    transmogrifier['urlopen']['auth-codes'].splitlines()
    if hasattr(modules['httplib'], status)
# Ignore Apache's "403: Forbidden" error
#   when directory indexes are denied and there's no DirectoryIndex
ignore-error = python:error.code in [${urlopen:auth-codes-python}] + [403]

[localopen]
blueprint = collective.transmogrifier.sections.inserter
key = string:_cache
# Only use local file as cache if it couldn't be retrieved via the URL
condition-unauthorized = [${urlopen:auth-codes-python}
    if item.get('_headers', {}).get('status', '').startswith(
        str(getattr(modules['httplib'], status)))]
condition = python:(${localopen:condition-unauthorized}
# Don't open driectories without default pages
    and not (item.get('_type') == 'Folder' and
             item.get('_headers', {}).get('code') ==
                 modules['httplib'].FORBIDDEN)
# Make sure local file exists
    and modules['os.path'].isfile(${localopen:value-python}))
value-python = modules['os.path'].join(
    transmogrifier['dirwalker']['dirname'], item['_old_paths'])
value = python:${localopen:value-python}

[redirected-url]
blueprint = collective.transmogrifier.sections.inserter
key = string:_redirected_url
condition = python:(item.get('_headers') and item.get('_url') and
        item['_url'].geturl() != item['_headers'].get('Url'))
value = python:modules['urlparse'].urlsplit(modules['urlparse'].urljoin(
      transmogrifier['url']['root'], item['_headers']['Url']))

[is-external]
blueprint = collective.transmogrifier.sections.inserter
key = string:_is_external
url = (item.get('_redirected_url') or item.get('_url'))
# Prefer the URL resulting from any redirects
condition = python:(${is-external:url} and
    not ${is-external:url}.geturl().startswith(transmogrifier['url']['root']))
value = python:True

[remoteUrl]
blueprint = collective.transmogrifier.sections.inserter
key = string:remoteUrl
condition = python:(not item.get('_type') and 'remoteUrl' not in item and (
# Use Links for nav elements to external URLs or already crawled internal URLs
        not item.get('excludeFromNav', True) and item.get('_url')
        and (not item.get('_is_defaultpage')
             and item['_url'].geturl().rstrip('/') in
             transmogrifier.__annotations__.get('xmlwalker.paths', {})))
# Use a link for temporary redirects
    or item.get('_headers', {}).get('Redirect-Status', '').startswith('302'))
value = python:((item.get('_is_external') and ${is-external:url}.geturl())
    or ${is-external:url}.path)

[redirect-old-path]
blueprint = collective.transmogrifier.sections.inserter
condition-python = item.get('_headers', {}).get(
    'Redirect-Status', '').startswith('301')
condition = python:'_path' in item and ${redirect-old-path:condition-python}
key = string:_old_paths
value = python:[item['_path']]

[url-redirect-path]
blueprint = collective.transmogrifier.sections.inserter
condition = python:item.get(
    '_redirected_url') and ${redirect-old-path:condition-python}
key = string:_plone.app.transmogrifier.redirector_path
value = python:(not item['_redirected_url'].geturl().startswith('${url:root}')
    and item['_redirected_url'].geturl()) or
    item['_redirected_url'].geturl()[len('${url:root}'):]

[redirect-cleanup]
blueprint = collective.transmogrifier.sections.manipulator
condition = exists:item/_plone.app.transmogrifier.redirector_path
delete = _path

[parse]
blueprint = collective.transmogrifier.sections.inserter
key = string:_tree
condition = python:(item.get('_headers') and item.get('_cache')
    and item['_headers'].get('content-type', '').startswith('text/html')
# Permanent redirects are not content, just in plone.app.redirector    
    and not ${redirect-old-path:condition-python})
value = python:modules['lxml.etree'].parse(
    item['_cache'], modules['lxml.html'].HTMLParser(
        encoding=item['_headers'].getparam('charset') or 'utf-8'),
    base_url=item['_url'].path)

[empty-tree]
blueprint = collective.transmogrifier.sections.manipulator
condition = not:item/_tree/getroot|nothing
delete = _tree

[absolute-links]
blueprint = collective.transmogrifier.sections.inserter
key = string:_absolute_links
condition = python:'_tree' in item and item[
    '_tree'].getroot().make_links_absolute()
value = nothing


## Extract content data from XML trees

[title]
blueprint = collective.transmogrifier.sections.inserter
# Customise xpath to change title extraction
xpath = /html/head/title
# Keep nav title for folders
#   assume items without types will be folders with default pages when crawled
key = python:item.get('_type') == 'Folder' and '_defaultpage' or 'title'
# Keep nav title for links, use /head/title for everything else
condition = ${description:condition} and (
    not item.get('remoteUrl') or not item.get('title'))
value-python = u' '.join(element.text_content().strip() for element in
                         item['_tree'].xpath(options['xpath']))
value = python:${title:value-python}

[title-from-id]
blueprint = collective.transmogrifier.sections.inserter
key = string:title
condition = python:item.get('_id') and not item.get('title')
value = item/_id

[id]
blueprint = plone.app.transmogrifier.urlnormalizer
locale = string:en

[description]
blueprint = collective.transmogrifier.sections.inserter
key = string:description
xpath = /html/head/meta[@name='description']/@content
condition = python:'_tree' in item and item['_tree'].xpath(options['xpath'])
value = python:u' '.join(element.strip() for element in
    item['_tree'].xpath(options['xpath']))

[subject]
blueprint = collective.transmogrifier.sections.inserter
key = string:subject
xpath = /html/head/meta[@name='keywords']/@content
condition = ${description:condition}
value = python:u','.join(element.strip() for element in
    item['_tree'].xpath(options['xpath'])).split(',')

[modificationDate]
blueprint = collective.transmogrifier.sections.inserter
key = string:modificationDate
condition = python:'_headers' in item and item['_headers'].get('last-modified')
value = python:item['_headers']['last-modified']

[content]
blueprint = collective.transmogrifier.sections.inserter
key = string:_content
# Don't crawl Folders
condition = python:('_tree' in item and item.get('_type') != 'Folder'
# Don't crawl Links, also prevents loops on nav Link items
    and 'remoteUrl' not in item)
# Customize this xpath expression to isolate the content body elements
xpath = //*[@id='content' or contains(@class, 'content')]/*
value = python:item['_tree'].xpath(options['xpath'])

[html-file]
# Treat HTML URLs with no recognized content body as whole static HTML files
# without the Plone framing
blueprint = collective.transmogrifier.sections.inserter
key = string:_type
condition = python:(not item.get('_type') and item.get('_headers', {}).get(
    'content-type', '').startswith('text/html') and not item.get('_content')
    and not item.get('remoteUrl') and not item.get('_redirected_url'))
value = string:File

## Assemble the path and type

[type]
blueprint = collective.transmogrifier.sections.inserter
key = string:_type
# How much of the body to classify,
#   default to the OFS.Image.File linked Pdata chunk size
size = 65536
findTypeName = transmogrifier.context.content_type_registry.findTypeName(
# Use the extension of the original URL
    getattr(item.get('_url'), 'path', '')
# Remote URLs should be Links, use a *.url extension
    + (('remoteUrl' in item and not item.get('_is_defaultpage')
        and '.url') or ''),
# Use MIME type from respone
    item.get('_headers', {}).get('content-type', ''),
# Read only some of the file for classification
    'text' in item and item['text']
    or ('_cache' in item and open(item['_cache']).read(${type:size}))
    or '')
condition = python:item.get('_path', True) and (not item.get('_type') and
    not ${redirect-old-path:condition-python} and ${type:findTypeName})
value = python:${type:findTypeName}

[path]
blueprint = collective.transmogrifier.sections.inserter
key = string:_path
condition = python:item.get('_url'
    ) and '_plone.app.transmogrifier.redirector_path' not in item
dirname = item.get('_parent_path', modules['posixpath'].dirname(
    item.get('_url') and modules['urllib'].unquote(item['_url'].path)
     or item.get('remoteUrl',
         item.get('_path', transmogrifier['url']['path']))))
basename = ((item.get('_type') not in ('File', 'Image') and item.get('_id'))
     or modules['posixpath'].basename(
        item.get('_url') and modules['urllib'].unquote(item['_url'].path)
        or item.get('remoteUrl', item.get('_path'))))
value = python:modules['posixpath'].join(
# Content links and dirwalker items have no structure
    item.get('excludeFromNav', True) and modules['posixpath'].join(
        ${path:dirname}, modules['posixpath'].dirname(
            modules['urllib'].unquote(item['_url'].path)))
    or ${path:dirname}, ${path:basename})

[drop-seen-paths]
blueprint = collective.transmogrifier.sections.condition
condition = python:'_url' not in item or (
# Don't create Links for content elements
    (not item.get('excludeFromNav', True) or
     item['_url'].geturl().rstrip('/') not in
     transmogrifier.__annotations__.get('xmlwalker.paths', {}))
# Don't re-process nav elements for the same path and URL
    and (item.get('_path', '').strip('/') not in
    transmogrifier.__annotations__.get('xmlwalker.paths', {}).get(
        item['_url'].geturl().rstrip('/'), set())))

[seen]
blueprint = collective.transmogrifier.sections.inserter
key = string:_seen
condition = python:(item.get('_url') and '_path' in item
    and item.get('_type') != 'Folder' and (
# Just add the seen path, don't insert a key
    item['_url'].geturl().rstrip('/') in
    transmogrifier.__annotations__.get('xmlwalker.paths', {})
    or transmogrifier.__annotations__.setdefault(
       'xmlwalker.paths', {}).setdefault(
           item['_url'].geturl().rstrip('/'), set()).add(
               item['_path'].strip('/'))))
value = python:True

[context]
blueprint = collective.transmogrifier.sections.inserter
condition = python:('_path' in item
    or '_plone.app.transmogrifier.redirector_path' in item)
key = string:_context
value = python: item.get('_path', item.get(
    '_plone.app.transmogrifier.redirector_path'))

[resolve-context]
blueprint = collective.transmogrifier.sections.pathresolver
keys = _context

[unique]
blueprint = collective.transmogrifier.sections.inserter
key = string:_path
condition = python:(item.get('_context') is not None
    and item.get('_path', '') not in ('', '/')
    and item.get('_type') != 'Folder'
# Shoule be a new object if the previous item's path has a different URL
    and (item.get('_url') and not item.get('_seen')))
value = python:modules['posixpath'].join(
    modules['posixpath'].dirname(item['_path']),
    modules['zope.container.interfaces'].INameChooser(
        item['_context'].aq_parent).chooseName(modules['posixpath'].basename(
            item['_path']), item['_context']))


## Get links to crawl from content body next

[walk-content]
blueprint = collective.transmogrifier.sections.xmlwalker
trees = python:'_tree' in item and item.get('_content')
xpath = (@href | @src)[.!='' and not(starts-with(., '#'))]
type-key = nothing
is-default-page-key = nothing
attribs = ['href', 'src']
element-keys =
    _old_paths
    _url
    _is_external
    title

    _content_element
    _parent
    excludeFromNav

# Content links are always relative to crawled page
element-_parent = source_item
element-_content_element = nocall:element
element-excludeFromNav = python:True

# Extract information from walked element
# Normalize the absolute version of the link
element-_old_paths = python:[modules['posixpath'].abspath(
    modules['urlparse'].urljoin(
        source_item['_url'].path, modules['urlparse'].urlsplit(
            modules['urllib'].unquote(item.get('_type') == 'Folder' and
            modules['posixpath'].dirname(href.strip()) or
            href.strip())).path)) + (
        item.get('_type') == 'Folder' and '/' or '')
    for href in element.xpath("${walk-content:xpath}")
# link has some path element, no empty links or fragment-only links
    if (modules['urlparse'].urlsplit(href.strip()).netloc or
        modules['urlparse'].urlsplit(href.strip()).path)]
element-_url = python:item['_old_paths'] and (item.update(
    _url=modules['urlparse'].urlsplit(
        element.xpath("${walk-content:xpath}")[0].strip()))
    or modules['urlparse'].SplitResult(
        item['_url'].scheme or transmogrifier['url']['scheme'],
        item['_url'].netloc or transmogrifier['url']['netloc'],
        modules['urllib'].quote(
            item.get('_type') == 'Folder' and modules['posixpath'].join(
                item['_old_paths'][0], modules['posixpath'].basename(
                     item['_url'].path)) or item['_old_paths'][0]), '', ''))
element-_is_external = python:(item['_url'] and not
    item['_url'].geturl().startswith(transmogrifier['url']['root']))

element-title = python:unicode(element.text_content().strip()
                               or element.attrib.get('alt', '').strip())


## Get related items from first left nav

[relatedItems-tree]
blueprint = collective.transmogrifier.sections.inserter
key = string:_relatedItems
condition = python:False
xpath = //*[contains(@class, 'nav-list')][2]
value = python:item['_tree'].xpath(options['xpath'])

[walk-relatedItems]
blueprint = collective.transmogrifier.sections.xmlwalker
trees = item/_relatedItems|nothing
xpath = ${walk-content:xpath}
type-key = ${walk-content:type-key}
is-default-page-key = ${walk-content:is-default-page-key}
element-keys = ${walk-content:element-keys}

# related items links are always relative to crawled page
element-_parent = ${walk-content:element-_parent}
element-_content_element = ${walk-content:element-_content_element}
element-excludeFromNav = ${walk-content:element-excludeFromNav}

element-_old_paths = ${walk-content:element-_old_paths}
element-_url = ${walk-content:element-_url}
element-_is_external = ${walk-content:element-_is_external}
element-title = ${walk-content:element-title}

[relatedItems]
blueprint = collective.transmogrifier.sections.inserter
key = string:relatedItems
condition = python:('relatedItems' not in item and '_relatedItems' in item
    and item['_tree'].xpath("${relatedItems:xpath}"))
xpath = (${relatedItems-tree:xpath}//*/@href\
    | ${relatedItems-tree:xpath}//*/@src)[.!='' and not(starts-with(., '#'))]
value = python:[modules['posixpath'].abspath(modules['urlparse'].urljoin(
    modules['posixpath'].join('/', item['_parent_path']), href.strip())
    ).lstrip('/') for href in item['_tree'].xpath("${relatedItems:xpath}")]


## Get links to crawl from left navigation list

[left-nav]
blueprint = collective.transmogrifier.sections.inserter
key = string:_left_nav
condition = ${nav:condition}
# Customize this xpath expression to isolate the left navigation elements
xpath = //*[contains(@class, 'nav-list')][1]
value = python:item['_tree'].xpath(options['xpath'])

[walk-left-nav]
blueprint = collective.transmogrifier.sections.xmlwalker
trees = item/_left_nav|nothing
cache = true
element-keys =
    _old_paths
    _url
    _is_external
    title
    excludeFromNav

element-_old_paths = ${walk-content:element-_old_paths}
element-_url = ${walk-content:element-_url}
element-_is_external = ${walk-content:element-_is_external}
element-title = ${walk-content:element-title}
element-excludeFromNav = python:False


## Get links to crawl from site nav first

[nav]
blueprint = collective.transmogrifier.sections.inserter
key = string:_nav
condition = python:'_tree' in item and 'remoteUrl' not in item
# Customize this xpath expression to isolate the navigation elements
xpath = //*[contains(@class, 'navbar')]//ul[contains(@class, 'nav')]
value = python:item['_tree'].xpath(options['xpath'])

[walk-nav]
blueprint = collective.transmogrifier.sections.xmlwalker
trees = item/_nav|nothing
cache = true
element-keys = ${walk-left-nav:element-keys}

element-_old_paths = ${walk-content:element-_old_paths}
element-_url = ${walk-content:element-_url}
element-_is_external = ${walk-content:element-_is_external}
element-title = ${walk-content:element-title}

element-excludeFromNav = ${walk-left-nav:element-excludeFromNav}


## Free/remove memory intensive XML tree references
[delete-trees]
blueprint = collective.transmogrifier.sections.manipulator
delete =
    _tree
    _nav
    _left_nav
    _relatedItems


## Send child items back to the top of the crawl loop

[drop-matching]
blueprint = collective.transmogrifier.sections.condition
patterns =
    *.htaccess
    sitemap.xml
    sitemap.xml.gz
    *.svn
    *.git
    *.gitignore
    *.svn/*
    *.git/*
condition = python:not [
   pattern for pattern in set("""${drop-matching:patterns}""".split())
   if modules['fnmatch'].fnmatch(
       item.get('_path', getattr(item.get('_url'), 'path', '').lstrip('/')),
       pattern)]

[log-dropped]
blueprint = collective.transmogrifier.sections.logger
level = INFO
condition = not:${drop:condition}
key = _url

[drop]
blueprint = collective.transmogrifier.sections.condition
# Only drop items to be crawled
condition = python:('_url' not in item
# Only drop items to crawl that haven't already been crawled
    or '_cache' in item or (
# Drop external links in content, let links in nav become Link content
    not item.get('_is_external') or not item.get('excludeFromNav', True)))

[log-crawled]
blueprint = collective.transmogrifier.sections.logger
level = INFO
condition = ${crawl:condition}
key = _url

[crawl]
blueprint = collective.transmogrifier.sections.listappender
condition = python:'_cache' not in item and item.get('_url')
section = crawled


## Add the content

[folders]
blueprint = collective.transmogrifier.sections.folders

[content-redirect-path]
blueprint = collective.transmogrifier.sections.manipulator
# Dont add redirects for links
condition = exists:item/_path
keys = _path
destination = string:_plone.app.transmogrifier.redirector_path

[update-redirects]
blueprint = plone.app.transmogrifier.redirector
path-key =

[container]
# If the path dirname is not a Folder, use it's parent
blueprint = collective.transmogrifier.sections.inserter
key-name = _path
key = options/key-name
condition = python:(options['key-name'] in item and modules[
     'collective.transmogrifier.utils'].traverse(
         transmogrifier.context, modules['posixpath'].dirname(
             item[options['key-name']])) is not None and modules[
     'collective.transmogrifier.utils'].traverse(
         transmogrifier.context, modules['posixpath'].dirname(
             item[options['key-name']])).getPortalTypeName() != 'Folder')
value = python:modules['posixpath'].join(
    modules['posixpath'].dirname(modules['posixpath'].dirname(
        item[options['key-name']])),
    modules['posixpath'].basename(item[options['key-name']]))

[container-redirect]
blueprint = ${container:blueprint}
key-name = _plone.app.transmogrifier.redirector_path
key = ${container:key}
condition = ${container:condition}
value = ${container:value}

[excludeFromNav]
# Exclude all items walked from the directory, walk-nav will include only nav
blueprint = collective.transmogrifier.sections.inserter
key = string:excludeFromNav
value = python:True
condition = python:item.get('_context') is None and 'excludeFromNav' not in item

[drop-construct]
blueprint = collective.transmogrifier.sections.manipulator
# Do not add content for the portal itself
condition = python:'_path' in item and item.get('_path', '') in ('', '/')
delete = _type

[log-content]
blueprint = collective.transmogrifier.sections.logger
level = INFO
condition = python:item.get('_path') and item.get('_type')
key = _path

[disable_versioning]
blueprint = plone.app.transmogrifier.versioning.disable

[construct]
blueprint = collective.transmogrifier.sections.constructor

[enable_versioning]
blueprint = plone.app.transmogrifier.versioning.enable


## Defer some keys that need redirector entries from other content

[log-deferred]
blueprint = collective.transmogrifier.sections.logger
level = INFO
condition = ${defer-links:condition}
key = _path

[defer-links]
blueprint = collective.transmogrifier.sections.listappender
condition = python:item.get('_url') and (
    '_content' in item or item.get('relatedItems') or item.get('remoteUrl'))
section = deferred
# Defer all field keys so that only one update is done
# '_content' will become 'text' after links have been updated from redirector
keys = python:[key for key in item
    if key == '_content' or not key.startswith('_')]
copy-keys = python:['_path', '_content_element']

[add-redirects]
blueprint = plone.app.transmogrifier.redirector
path-key = _plone.app.transmogrifier.redirector_path
update-path-keys = 

[resolve]
blueprint = collective.transmogrifier.sections.pathresolver
keys =
    _context
    relatedItems


[text]
blueprint = collective.transmogrifier.sections.inserter
key = string:text
condition = python:(item.get('_type') != 'Folder' and '_content' in item
    and 'remoteUrl' not in item)
value = python:u'\n'.join([modules['lxml.etree'].tostring(
        element, method='html', encoding=unicode, pretty_print=True)
    for element in item['_content']])

[delete-content]
blueprint = collective.transmogrifier.sections.manipulator
condition = exists:item/_content
delete = _content

# Open the cache as a real file for the File and Image types fields
[file]
blueprint = collective.transmogrifier.sections.inserter
key = python:item.get('_type') == 'Image' and 'image' or 'file'
condition = python:('text' not in item and '_cache' in item
    and item.get('_type') in ('File', 'Image'))
value = python:open(item['_cache'])


[set-local-roles]
blueprint = collective.transmogrifier.sections.inserter
key = nothing
condition = python:(item.get('_login') and item.get('_local_roles') and
    item.get('_context') is not None and item['_context'].manage_setLocalRoles(
        item['_login'], item['_local_roles']))
value = nothing

[update]
blueprint = plone.app.transmogrifier.atschemaupdater

# Close and delete file references to avoid too many open files
[close]
blueprint = collective.transmogrifier.sections.manipulator
condition = python:(('file' in item and item['file'].close())
    or ('image' in item and item['image'].close()) or True)
delete =
    file
    image

[transitions]
blueprint = collective.transmogrifier.sections.inserter
key = string:_transitions
value = python:["publish"]
condition = python:('_transitions' not in item and '_url' in item
# Don't publish types without workflow
    and item.get('_type') not in ('File', 'Image')
# Don't publish if response had an unauthorized status code
    and not (${localopen:condition-unauthorized}))


[publish]
blueprint = plone.app.transmogrifier.workflowupdater


[defaultpage]
blueprint = plone.app.transmogrifier.urlnormalizer
source-key = _defaultpage
destination-key = string:_defaultpage
locale = string:en

[browserdefault]
blueprint = plone.app.transmogrifier.browserdefault


[reindexobject]
blueprint = plone.app.transmogrifier.reindexobject


[savepoint]
blueprint = collective.transmogrifier.sections.savepoint


## Debugging tools

[debug]
blueprint = collective.transmogrifier.sections.logger
# Change to True to log full items for debugging
condition = python:False
level = INFO
delete = text

[breaker]
blueprint = collective.transmogrifier.sections.breakpoint
# Change to True to log full items for debugging
condition = python:False
