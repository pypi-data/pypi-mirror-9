<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Scrapple 0.2.3 documentation &mdash; Scrapple  documentation</title>
    
    <link rel="stylesheet" href="_static/default.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="top" title="Scrapple  documentation" href="#" />
    <link rel="next" title="Web page structure" href="concepts/structure.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="concepts/structure.html" title="Web page structure"
             accesskey="N">next</a> |</li>
        <li><a href="#">Scrapple  documentation</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="scrapple-version-documentation">
<h1>Scrapple 0.2.3 documentation<a class="headerlink" href="#scrapple-version-documentation" title="Permalink to this headline">¶</a></h1>
<div class="section" id="synopsis">
<h2>Synopsis<a class="headerlink" href="#synopsis" title="Permalink to this headline">¶</a></h2>
<p>The Internet is a huge source of information. Several people may use data from the Internet to perform various activities, like research or analysis. Data extraction is a primary step involved in data mining and analysis. Extracting content from structured web pages is a vital task to be performed when the Internet is the principal source of data.</p>
<p>The current standards in web structure involve the use of CSS selectors or XPath expressions to select particular tags from which information can be extracted. Web pages are structured as element trees which can be parsed to traverse through the tags. This tree structure, which represents tags as parent/children/siblings, is very useful when tags should be represented in terms of the rest of the web page structure.</p>
<p>Scrapple is a project aimed at designing a framework for building web content extractors. Scrapple uses key-value based configuration files to define parameters to be considered in generating the extractor. It considers the base page URL, selectors for the data to be extracted, and the selector for the links to be crawled through. At its core, Scrapple abstracts the implementation of the extractor, focussing more on representing the selectors for the required tags. Scrapple can be used to generate single page content extractors or link crawlers.</p>
</div>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>The Internet is a huge source of information. Several people may use data from the Internet to perform various activities, like research or analysis. However, there are two primary issues involved with using data from the Internet :</p>
<ul class="simple">
<li>You may not have any way to get information from a particular website, i.e, it may not provide an API for accessing the data.</li>
<li>Even if an API is provided, it may not give all the data needed. It is possible that there may be some data that is present on the web interface, but not provided through the API.</li>
</ul>
<p>This is where web scrapers and web crawlers come in.</p>
<div class="section" id="web-scrapers-web-crawlers">
<h3>Web scrapers &amp; web crawlers<a class="headerlink" href="#web-scrapers-web-crawlers" title="Permalink to this headline">¶</a></h3>
<p><strong>Web scrapers</strong>, also called <strong>extractors</strong>, are used to extract content from any particular page. They may use CSS Selectors or XPath expressions to point to a particular tag on the HTML structure of the page, and extract the content from that tag. The content extracted could be text from <tt class="docutils literal"><span class="pre">&lt;div&gt;</span></tt> tags, links from <tt class="docutils literal"><span class="pre">&lt;a&gt;</span></tt> tags, and so on.</p>
<p><strong>Web crawlers</strong> are scripts that go through multiple links from a single base page. Given a base URL, it uses this page as an index page to many different pages. It goes through each of these pages, extracting the required content along the way.</p>
<p>Scrapers and crawlers can be written to extract necessary content from any page that you would need information from.</p>
</div>
<div class="section" id="objective">
<h3>Objective<a class="headerlink" href="#objective" title="Permalink to this headline">¶</a></h3>
<p>Scrapple helps to reduce the hassle in manually writing the scripts needed to extract the required content. It involves the use of a configuration file that specifies property-value pairs of various parameters involved in constructing the required script.</p>
<p>The configuration file is a JSON document, consisting of the required key-value pairs. The user specifies the base URL of the page to work on, and also the tags of the data to be extracted. The user has a choice between CSS selectors and XPath expressions for specifying the target tags. Once the target tags have been specified, the other parameters are filled and the configuration file is completed. This configuration file is used by Scrapple to generate the required script and the execution is performed to generate the output of the scraper as a CSV/JSON document (depending on the argument passed while running the script). Thus, the user can obtain data they need without having extensive programming expertise to manually write the scripts required.</p>
</div>
<div class="section" id="application-of-scrapple">
<h3>Application of Scrapple<a class="headerlink" href="#application-of-scrapple" title="Permalink to this headline">¶</a></h3>
<p>Scrapple can be used to create custom web content extractors, to build datasets required for various applications.</p>
<p>For example, to perform an analysis of the <a class="reference external" href="http://github.com/trending/">trending repositories on GitHub</a>, the user would require a dataset of statistics, like commits on each repository, number of followers of the repository etc. To obtain this data, the user could use Scrapple to create an extractor, that would crawl through the repository list on the page and extract the required data for each repository.</p>
<p>Scrapple is experimented with an <a class="reference internal" href="#section-experimentation"><em>example of talk listings from Pyvideo</em></a>.</p>
</div>
<div class="section" id="the-inspiration-behind-scrapple">
<h3>The inspiration behind Scrapple<a class="headerlink" href="#the-inspiration-behind-scrapple" title="Permalink to this headline">¶</a></h3>
<p>Scrapple is based on the best ideas involved in two projects :</p>
<ul class="simple">
<li>Scrapy [1] : Scrapy is an application framework, designed to build web spiders that extract structured web data.</li>
<li>Ducky [2] : Ducky is a semi-automatic web wrapper, which uses a configuration file to define extraction rules, and extract data accordingly.</li>
</ul>
</div>
</div>
<div class="section" id="project-timeline">
<h2>Project timeline<a class="headerlink" href="#project-timeline" title="Permalink to this headline">¶</a></h2>
<p>The overall project work can be summarized in this Gantt chart.</p>
<div class="figure align-center">
<img alt="Gantt chart" src="_images/gantt.png" />
<p class="caption">Gantt chart - Project timeline</p>
</div>
<p>The metrics on <a class="reference external" href="http://github.com/scrappleapp/scrapple">the Scrapple GitHub repository</a> can be used to visually represent the contributions to the project over the duration of the project work.</p>
<div class="figure align-center">
<img alt="GitHub commits" src="_images/commits.png" />
<p class="caption">Commit frequency on the project</p>
</div>
<div class="figure align-center">
<img alt="Weekly contributions" src="_images/weekly.png" />
<p class="caption">Weekly contributions to the project repository</p>
</div>
</div>
<div class="section" id="review-of-existing-systems">
<h2>Review of existing systems<a class="headerlink" href="#review-of-existing-systems" title="Permalink to this headline">¶</a></h2>
<p>Data extraction process from the web can be classified based on the selectors used. Selectors can be CSS or XPath expressions. CSS selectors are said to be faster and are used by many browsers. Ducky [2] uses CSS selectors for extracting data from pages that are similarly structured.</p>
<p>On the other hand, XPath expressions are more reliable, handles text recognition better and a powerful option to locate elements when compared to CSS selectors. Many researches are going on presently in this topic. Oxpath [3] provides an extension for XPath expressions. The system created by V. Crescenzi, P. Merialdo, and D. Qiu [4] uses XPath expressions for locating the training data to create queries posed to the workers of a crowd sourcing platform.</p>
<p>Systems like Ducky and Deixto [5] use the concept of Configuration files where the user inputs the simple details like base pages, a “next” column if there are multiple pages to be parsed. Deixto uses the concept of tag filtering where the unnecessary html tags can be ignored when the DOM (Document Object Model) tree is created.</p>
<p>Scrapy [1], an open source project, provides the framework for web crawlers and extractors. This framework provides support for spider programs that are manually written to extract data from the web. It uses XPath expression to locate the content. The output formats of Ducky and Scrapy include XML, CSV and JSON files.</p>
</div>
<div class="section" id="concepts">
<h2>Concepts<a class="headerlink" href="#concepts" title="Permalink to this headline">¶</a></h2>
<p>Creating web content extractors requires a good understanding of the following topics :</p>
<ul class="simple">
<li><a class="reference internal" href="concepts/structure.html"><em>Web page structure</em></a></li>
<li><a class="reference internal" href="concepts/selectors.html"><em>Selector expressions</em></a></li>
<li><a class="reference internal" href="concepts/formats.html"><em>Data formats</em></a></li>
</ul>
<p>A brief overview of the concepts behind Scrapple is given.</p>
<div class="toctree-wrapper compound">
</div>
</div>
<div class="section" id="requirement-specification-installation-instructions">
<h2>Requirement specification &amp; Installation instructions<a class="headerlink" href="#requirement-specification-installation-instructions" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
</div>
</div>
<div class="section" id="interaction-scenarios">
<h2>Interaction scenarios<a class="headerlink" href="#interaction-scenarios" title="Permalink to this headline">¶</a></h2>
<p>The primary use cases in Scrapple are the execution of the <a class="reference internal" href="framework/commands.html#framework-commands"><em>commands</em></a> provided by the framework. A general idea of the execution of these commands and the relation between the various modules of the framework can be understood through a study of the interaction scenarios for each of the commands.</p>
<p>Basic sequence diagrams for the execution for each command can be represented as such. A more detailed explanation of the execution of the commands is provided in the <a class="reference internal" href="implementation/commands.html#implementation-commands"><em>commands implementation</em></a> section.</p>
<div class="figure align-center">
<img alt="Genconfig sequence diagram" src="_images/genconfig.jpg" />
<p class="caption"><a class="reference internal" href="framework/commands.html#command-genconfig"><em>Genconfig command</em></a></p>
</div>
<div class="figure align-center">
<img alt="Generate sequence diagram" src="_images/generate.jpg" />
<p class="caption"><a class="reference internal" href="framework/commands.html#command-generate"><em>Generate command</em></a></p>
</div>
<div class="figure align-center">
<img alt="Run sequence diagram" src="_images/run.jpg" />
<p class="caption"><a class="reference internal" href="framework/commands.html#command-run"><em>Run command</em></a></p>
</div>
<div class="figure align-center">
<img alt="Web sequence diagram" src="_images/web.jpg" />
<p class="caption"><a class="reference internal" href="framework/commands.html#command-web"><em>Web command</em></a></p>
</div>
</div>
<div class="section" id="implementation-methodology">
<h2>Implementation methodology<a class="headerlink" href="#implementation-methodology" title="Permalink to this headline">¶</a></h2>
<p>This section deals with how Scrapple works - the architecture of the Scrapple framework, the commands and options provided by the framework and the specification of the configuration file.</p>
<p>It also deals with the implementation of the Scrapple framework. This includes an explanation of the classes involved in the framework, the interaction scenarios for each of the commands supported by Scrapple, and utility functions that form a part of the implementation of the extractor.</p>
<div class="toctree-wrapper compound">
</div>
</div>
<div class="section" id="experimentation-results">
<span id="section-experimentation"></span><h2>Experimentation &amp; Results<a class="headerlink" href="#experimentation-results" title="Permalink to this headline">¶</a></h2>
<p>In this section, some experiments with Scrapple are provided. There are two main types of tools that can be implemented with the Scrapple framework :</p>
<ul class="simple">
<li><a class="reference internal" href="intro/tutorials/single_linear.html"><em>Single page linear scrapers</em></a></li>
<li><a class="reference internal" href="intro/tutorials/link_crawler.html"><em>Link crawlers</em></a></li>
</ul>
<p>Once you&#8217;ve <a class="reference internal" href="intro/install.html"><em>installed Scrapple</em></a>, you can see the list of available <a class="reference internal" href="framework/commands.html#framework-commands"><em>commands</em></a> and the related options using the command</p>
<p><tt class="docutils literal"><span class="pre">$</span> <span class="pre">scrapple</span> <span class="pre">--help</span></tt></p>
<p>The <a class="reference internal" href="framework/config.html#framework-config"><em>configuration file</em></a> is the backbone of Scrapple. It specifies the base page URL, selectors for the data extraction, the follow link for the link crawler and several other parameters.</p>
<p>Examples for each type are given.</p>
<div class="toctree-wrapper compound">
</div>
</div>
<div class="section" id="conclusion-future-work">
<h2>Conclusion &amp; Future Work<a class="headerlink" href="#conclusion-future-work" title="Permalink to this headline">¶</a></h2>
<p>The goal of Scrapple is to provide a generalized solution to the problem of web content extraction. This framework requires a basic understanding of web page structure, which is necessary to write the necessary selector expressions. Using these selector expressions, the required web content extractors can be implemented to generate the desired datasets.</p>
<p>Experimentation with a wide range of websites gave consistently accurate results, in terms of the generated dataset. However, larger crawl jobs took a lot of time to complete and it was necessary to run the execution in one stretch. Scrapple could be improved to provide restartable crawlers, using caching mechanisms to keep track of the position in the URL frontier. Tag recommendation systems could also be implemented, using complex learning algorithms, though there would be a trade-off on accuracy.</p>
<p>Improvements to the existing features would include a complete development of the web based configuration file editor, to support editing configuration files for link crawlers.</p>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p>[1] Scrapy: A fast and powerful scraping and web crawling framework.[Online] Available: <a class="reference external" href="https://www.scrapy.org">https://www.scrapy.org</a></p>
<p>[2] Kei Kanaoka, Yotaro Fujii and Motomichi Toyama. Ducky: A Data Extraction System for Various Structured Web Documents. In Proceedings of the 18th International Database Engineering &amp; Applications Symposium, IDEAS ’14, pages 342-347, New York, NY, USA, 2014. ACM</p>
<p>[3] T.Furche, G. Gottlob, G. Grasso, C. Schallhart, and A. Sellers. Oxpath: A language for scalable data extraction, automation, and crawling on the deep web. The VLDB Journal, 22(1):47–72, Feb. 2013</p>
<p>[4] V.Crescenzi, P. Merialdo, and D. Qiu. Alfred: Crowd assisted data extraction. In Proceedings of the 22Nd International Conference on World Wide Web Companion, WWW ’13 Companion, pages 297–300, Republic and Canton of Geneva, Switzerland, 2013. International World Wide Web Conferences Steering Committee.</p>
<p>[5] F.Kokkoras, K. Ntonas, and N. Bassiliades. Deixto: A web data extraction suite. In Proceedings of the 6th Balkan Conference in Informatics, BCI ’13, pages 9–12, New York, NY, USA, 2013. ACM.</p>
<p>[6] Elements and Element Trees [Online]. Available: <a class="reference external" href="http://effbot.org/zone/element.htm">http://effbot.org/zone/element.htm</a></p>
<p>[7] Selectors[Online]. Available: <a class="reference external" href="http://www.w3.org/TR/CSS21/selector.html">http://www.w3.org/TR/CSS21/selector.html</a></p>
<p>[8] XML Path language(XPath)[Online]. Available: <a class="reference external" href="http://www.w3.org/TR/xpath/">http://www.w3.org/TR/xpath/</a></p>
<p>[9] XPath support in ElementTree[Online]. Available: <a class="reference external" href="http://effbot.org/zone/element-xpath.htm">http://effbot.org/zone/element-xpath.htm</a></p>
</div>
<div class="section" id="appendix">
<h2>Appendix<a class="headerlink" href="#appendix" title="Permalink to this headline">¶</a></h2>
<div class="section" id="plagiarism-report">
<h3>Plagiarism report<a class="headerlink" href="#plagiarism-report" title="Permalink to this headline">¶</a></h3>
<img alt="Plagiarism report" class="align-center" src="_images/plagiarism.jpg" />
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="#">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Scrapple 0.2.3 documentation</a><ul>
<li><a class="reference internal" href="#synopsis">Synopsis</a></li>
<li><a class="reference internal" href="#introduction">Introduction</a><ul>
<li><a class="reference internal" href="#web-scrapers-web-crawlers">Web scrapers &amp; web crawlers</a></li>
<li><a class="reference internal" href="#objective">Objective</a></li>
<li><a class="reference internal" href="#application-of-scrapple">Application of Scrapple</a></li>
<li><a class="reference internal" href="#the-inspiration-behind-scrapple">The inspiration behind Scrapple</a></li>
</ul>
</li>
<li><a class="reference internal" href="#project-timeline">Project timeline</a></li>
<li><a class="reference internal" href="#review-of-existing-systems">Review of existing systems</a></li>
<li><a class="reference internal" href="#concepts">Concepts</a></li>
<li><a class="reference internal" href="#requirement-specification-installation-instructions">Requirement specification &amp; Installation instructions</a></li>
<li><a class="reference internal" href="#interaction-scenarios">Interaction scenarios</a></li>
<li><a class="reference internal" href="#implementation-methodology">Implementation methodology</a></li>
<li><a class="reference internal" href="#experimentation-results">Experimentation &amp; Results</a></li>
<li><a class="reference internal" href="#conclusion-future-work">Conclusion &amp; Future Work</a></li>
<li><a class="reference internal" href="#references">References</a></li>
<li><a class="reference internal" href="#appendix">Appendix</a><ul>
<li><a class="reference internal" href="#plagiarism-report">Plagiarism report</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Next topic</h4>
  <p class="topless"><a href="concepts/structure.html"
                        title="next chapter">Web page structure</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="_sources/index.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="concepts/structure.html" title="Web page structure"
             >next</a> |</li>
        <li><a href="#">Scrapple  documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2014, Alex Mathew, Harish Balakrishnan.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.3.
    </div>
  </body>
</html>