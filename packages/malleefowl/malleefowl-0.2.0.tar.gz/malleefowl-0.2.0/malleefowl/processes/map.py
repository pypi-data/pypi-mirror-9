import types
from malleefowl.process import WPSProcess
import urllib
import xmltodict
from PIL import Image
from images2gif import writeGif
import dateutil.parser as date_parser
import StringIO

REQUEST = "service=WMS&version=1.3.0&request=GetCapabilities"

class GetWMSFromThreddsProcess(WPSProcess):
    """
    The process is not intended for use with the generic tool
    """
    def __init__(self):
       
        WPSProcess.__init__(self,
            identifier = "WMS.GetThreddsStructure",
            title = "WMS get thredds structure",
            version = "2014.09.01",
            metadata = [],
            abstract = "Walk through the thredds and return all WMS related urls")

        self.thredds_url = self.addLiteralInput(
            identifier = "thredds_url",
            title = "The url of the thredds",
            type = types.StringType,
            default = "http://localhost:8080/thredds",
            minOccurs = 1,
            maxOccurs = 1,
            )


        self.wms_json = self.addLiteralOutput(
            identifier = "wms_json",
            title = "WMS urls in json format.",
            type = types.StringType
            )

           

    def execute(self):
        thredds_url = self.thredds_url.getValue()

        found_baseaddress = [""]
        found_wms = []
        
        def add_paths(baseaddress):
            found_baseaddress.append(baseaddress)
            content = urllib.urlopen(baseaddress).read()
            relative_hrefs_raw = content.split("a href='")[1:]
            relative_hrefs = [x.split("'")[0] for x in relative_hrefs_raw if "catalog.html" in x]
            for relative_href in relative_hrefs:
                #no external references
                if "http:" in relative_href:
                    continue
                if relative_href[:1] == "/":#it is relative to root of tomcat
                    href = thredds_url + relative_href[len("/thredds"):]
                else:#it is relative to the currently selected directory
                    href = baseaddress[:-len("catalog.html")]+relative_href
                if "?" in href:#Found the reference to the dataset. Handled by another method.
                    add_wms(href)
                    continue
                #if parameters are in the get request then follow and extract the WMS (get capabilities)
                
                #cut of the 
                if href in found_baseaddress:
                    continue
                add_paths(href) 
        
        def add_wms(catalog_url):
            content = urllib.urlopen(catalog_url).read()
            #The filter is based on 4.3.22 version of THREDDS. It should be a request contain wms and 
            #not be the godiva link.
            hrefs = [x.split("'")[0] for x in content.split("a href='") if ("?" in x and 
                                                                            "/thredds/wms" in x and
                                                                            not "godiva" in x)]
            #It should only one entry remain, but perhaps somewhen a second wms reference is added. 
            for href in hrefs:
                found_wms.append(thredds_url + href[len("/thredds"):].split("?")[0])

        add_paths(thredds_url+"/catalog.html") 

        self.wms_json.setValue(str(found_wms))
        return 


class GetTimestepsProcess(WPSProcess):
    """
    The process is not intended for use with the generic tool
    """
    def __init__(self):
       
        WPSProcess.__init__(self,
            identifier = "WMS.GetTimesteps",
            title = "WMS get timesteps",
            version = "2014.08.28",
            metadata = [],
            abstract = "Extract the timesteps from the WMS description generated by ncWMS.")

        self.wms_url = self.addLiteralInput(
            identifier = "wms_url",
            title = "The WMS url",
            type = types.StringType,
            minOccurs = 1,
            maxOccurs = 1,
            )

        self.layer_name = self.addLiteralInput(
            identifier = "layer_name",
            title = "Name of the layer",
            type = types.StringType,
            )

        self.timesteps = self.addLiteralOutput(
            identifier = "timesteps",
            title = "Timesteps",
            type = types.StringType)

           

    def execute(self):
        wms_url = self.wms_url.getValue()
        layer_name = self.layer_name.getValue()
        cap_dict = get_capabilties_dict(wms_url)
        timesteps = get_timesteps(cap_dict, layer_name)

        self.timesteps.setValue(timesteps)
        return 

class GenerateGifAnimationMultiWMSProcess(WPSProcess):
    """
    The process is not intended for use with the generic tool
    """
    def __init__(self):
       
        WPSProcess.__init__(self,
            identifier = "WMS.GifAnimationMultiWMS",
            title = "WMS animate multiple WMS as gif",
            version = "2014.08.18",
            metadata = [],
            abstract = "Generate a gif from start to end time with the given aggregation.")

        self.wms_urls = self.addLiteralInput(
            identifier = "wms_urls",
            title = "The WMS urls",
            type = types.StringType,
            minOccurs = 1,
            maxOccurs = 100,
            )

        self.layer_name = self.addLiteralInput(
            identifier = "layer_name",
            title = "Name of the layer",
            type = types.StringType,
            )

        self.start_time = self.addLiteralInput(
            identifier = "start_time",
            title = "start time",
            type = types.StringType,
            )

        self.end_time = self.addLiteralInput(
            identifier = "end_time",
            title = "end time",
            type = types.StringType,
            )

        self.frame_duration = self.addLiteralInput(
            identifier = "frame_duration",
            title = "Frame duration",
            type = types.FloatType,
            default = 0.25,
            )

        self.aggregation = self.addLiteralInput(
            identifier = "aggregation",
            title = "aggregation",
            type = types.StringType,
            allowedValues = ["daily", "weekly", "monthly", "yearly"],
            )
        self.style = self.addLiteralInput(
            identifier = "style",
            title = "Style",
            type = types.StringType,
            default = "boxfill/rainbow",
            )

        self.height = self.addLiteralInput(
            identifier = "height",
            title = "height",
            type = types.StringType,
            default = "1024",
            )
        self.width = self.addLiteralInput(
            identifier = "width",
            title = "Width",
            type = types.StringType,
            default = "1024",
            )
        
        self.colorscalerange = self.addLiteralInput(
            identifier = "colorscalerange",
            title = "colorscalerange",
            type = types.StringType,
            minOccurs = 0,
            maxOccurs = 1,
            )
        self.animated_gif = self.addComplexOutput(
            identifier = "animated_gif",
            title = "Animated gif",
            metadata = [],
            formats = [{"mimeType": "image/gif"}],
            asReference = True,
            )

           

    def execute(self):
        wms_urls = self.wms_urls.getValue()
        layer_name = self.layer_name.getValue()
        start_time = self.start_time.getValue()
        end_time = self.end_time.getValue()
        aggregation = self.aggregation.getValue()
        frame_duration = self.frame_duration.getValue()
        style = self.style.getValue()
        width = self.width.getValue()
        height = self.height.getValue();
        colorscalerange = self.colorscalerange.getValue();
        
        DATA = {}#too keep every information to its source the url is used as key
        #get the capabilties for all processes
        global_timesteps = 0
        for wms_url in wms_urls:
            DATA[wms_url] = {}
            cap_dict = get_capabilties_dict(wms_url)
            timesteps = get_timesteps(cap_dict, layer_name)
            DATA[wms_url]["bbox"] = get_bbox(cap_dict, layer_name)
            DATA[wms_url]["crs"] = get_crs(cap_dict, layer_name)

            if global_timesteps == 0:
                global_timesteps = timesteps
            else:#search for timesets available in both
                global_timesteps = [x for x in global_timesteps if x in timesteps]
        if global_timesteps == 0:
            raise Exception("Could not find any timesteps for the animation")

        filtered_timesteps = filter_timesteps(global_timesteps, aggregation, start_time, end_time) 
        images = []
        cur = 0.0
        end = len(filtered_timesteps)+0.1#0.1 timestep for merging the gif
        for timestep in filtered_timesteps:
            self.status.set(msg = "Generating images", percentDone = cur/end*100.0, propagate = True)
            cur+= 1.0;
            merge_images = []
            for wms_url in wms_urls:
                bbox = DATA[wms_url]["bbox"]
                crs = DATA[wms_url]["crs"]
                image_stream = get_wms_image_stream(wms_url, bbox, timestep , layer_name, crs=crs,
                                                    style=style, width = width, height = height,
                                                    colorscalerange = colorscalerange)
                merge_images.append(Image.open(StringIO.StringIO(image_stream)))
            image = merge_images[0]
            image = image.convert("RGBA")
            for m_image in merge_images[1:]:
                m_image = m_image.convert("RGBA")
                image.paste(m_image, (0,0), m_image)
            images.append(image)
        filename =self.mktempfile(suffix=".gif") 
        writeGif(filename, images, duration=frame_duration, dither=0, repeat=True)
        fp = open(filename, "rb")
        self.animated_gif.setValue(fp)
        return 
################
#Helper methods#
################
"""
Filters timesteps such that the aggregation property is fulfilled. It does not fully 
follow ISO 8601, which is one of the reasons for potentially non equidistant timesteps. 
"""
def filter_timesteps(timesteps, aggregation="monthly", start=None, end=None):
    if (timesteps == None or len(timesteps) == 0):
        return []
    timesteps.sort()
    new_timesteps = []
    start_date = date_parser.parse(start)
    end_date = date_parser.parse(end)
    i = 0
    imax = len(timesteps)
    current_date = None
    #Find the start index to avoid rechecking for being greater than start date after that
    while i < imax:
        current_date = date_parser.parse(timesteps[i])
        if current_date < start_date:
            i+=1
        else:
            break
    #add the first timestep. In case no timestep is larger than start,
    #the last timestep will be returned.
    new_timesteps = [timesteps[i]]
    #To keep the end truncating simple it will be done in the processing loop. Finding the end
    #before processing is not likely to save time. 
    for j in range(i+1,imax):
        old_date = current_date
        current_date = date_parser.parse(timesteps[j])
        if current_date > end_date:
            break

        if old_date.year < current_date.year:
            new_timesteps.append(timesteps[j])
        elif old_date.year == current_date.year:
            if aggregation == "daily":
                if old_date.timetuple()[7] == current_date.timetuple()[7]:
                    continue
            elif aggregation == "weekly":
                if old_date.isocalendar()[1] == current_date.isocalendar()[1]:
                    continue
            elif aggregation == "monthly":
                if old_date.month == current_date.month:
                    continue
            elif aggregation == "yearly":
                if old_date.year == current_date.year:
                    continue
            # all checks passed
            new_timesteps.append(timesteps[j])
        else:
            continue
    return new_timesteps

def get_capabilties_dict(wms_url):
    xml = urllib.urlopen(wms_url+"?"+ REQUEST).read()
    cap_dict = xmltodict.parse(xml)
    return cap_dict

def get_timesteps(cap_dict, layer_name):
    layers = cap_dict["WMS_Capabilities"]["Capability"]["Layer"]["Layer"]["Layer"]
    timesteps = ""
    for layer in layers:
        if layer.get("Name","") == layer_name:
            timesteps = str(layer["Dimension"]["#text"])
    return timesteps.split(",")

def get_bbox(cap_dict, layer_name):
    layers = cap_dict["WMS_Capabilities"]["Capability"]["Layer"]["Layer"]["Layer"]
    for layer in layers:
        if layer.get("Name","") == layer_name:
            bbox = []
            bbox_dict = layer["EX_GeographicBoundingBox"]
            order = ["westBoundLongitude", "southBoundLatitude", "eastBoundLongitude", 
                     "northBoundLatitude"]
            for tag in order:
                #here one of the issues with xmltodict hits, as in contrast to layer["Dimension"]
                #it does not have the #text key, instead it returns it directly. 
                bbox.append(bbox_dict[tag])
    #turn the value from unicode to string...
    bbox = [str(x) for x in bbox]
    return bbox

def get_crs(cap_dict, layer_name):
    layers = cap_dict["WMS_Capabilities"]["Capability"]["Layer"]["Layer"]["Layer"]
    for layer in layers:
        if layer.get("Name","") == layer_name:
            return str(layer["BoundingBox"]["@CRS"])
    return None
     

def get_wms_image_stream(wms_url, bbox, timestep, layers,
                         width="1024",
                         height="1024",
                         version="1.3.0",
                         style ="boxfill/rainbow",
                         crs = "EPSG:4326",
                         colorscalerange = None,
                         ):
    #bbox_string = ",".join(bbox)
    bbox_string = "-180,-90,180,90"
    url = "".join([wms_url.split("?")[0], "?",
                   "request=GetMap&service=WMS",
                   "&TRANSPARENT=true", 
                   "&FORMAT=image/gif",
                   "&TIME=", timestep,
                   "&LAYERS=", layers,
                   "&version=", version,
                   "&BBOX=", bbox_string,
                   "&STYLES=", style,
                   "&CRS=", crs ,
                   "&WIDTH=", width,
                   "&HEIGHT=", height,
                   ])
    if(colorscalerange):
        url += "&COLORSCALERANGE="+colorscalerange;
    image_stream = urllib.urlopen(url).read()
    return image_stream

