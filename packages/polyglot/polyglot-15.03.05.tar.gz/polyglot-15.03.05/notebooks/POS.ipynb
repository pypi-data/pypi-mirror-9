{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of Speech tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of speech tagging task aims to assign every word/token in plain text a category that identifies the syntactic functionality of the word occurrence.\n",
    "\n",
    "Polyglot recognizes 17 parts of speech:\n",
    "\n",
    "- **ADJ**: adjective\n",
    "- **ADP**: adposition\n",
    "- **ADV**: adverb\n",
    "- **AUX**: auxiliary verb\n",
    "- **CONJ**: coordinating conjunction\n",
    "- **DET**: determiner\n",
    "- **INTJ**: interjection\n",
    "- **NOUN**: noun\n",
    "- **NUM**: numeral\n",
    "- **PART**: particle\n",
    "- **PRON**: pronoun\n",
    "- **PROPN**: proper noun\n",
    "- **PUNCT**: punctuation\n",
    "- **SCONJ**: subordinating conjunction\n",
    "- **SYM**: symbol\n",
    "- **VERB**: verb\n",
    "- **X**: other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Languages Coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models were trained on a combination of:\n",
    "- Original CONLL datasets after the tags were converted using the [universal POS tables](http://universaldependencies.github.io/docs/tagset-conversion/index.html).\n",
    "- Universal Dependencies 1.0 corpora whenever they are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Danish, Czech, Slovene, English, Bulgarian, Swedish, Portuguese, Dutch\n"
     ]
    }
   ],
   "source": [
    "from polyglot.downloader import downloader\n",
    "print(\", \".join(downloader.supported_languages(\"pos2\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Necessary Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[polyglot_data] Downloading package embeddings2.en to\n",
      "[polyglot_data]     /home/rmyeid/polyglot_data...\n",
      "[polyglot_data]   Package embeddings2.en is already up-to-date!\n",
      "[polyglot_data] Downloading package pos2.en to\n",
      "[polyglot_data]     /home/rmyeid/polyglot_data...\n",
      "[polyglot_data]   Package pos2.en is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "polyglot download embeddings2.en pos2.en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tag each word in the text with one part of speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from polyglot.text import Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blob = \"\"\"We will meet at eight o'clock on Thursday morning.\"\"\"\n",
    "text = Text(blob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can query all the tagged words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'We', u'PRON'),\n",
       " (u'will', u'VERB'),\n",
       " (u'meet', u'VERB'),\n",
       " (u'at', u'ADP'),\n",
       " (u'eight', u'NUM'),\n",
       " (u\"o'clock\", u'NOUN'),\n",
       " (u'on', u'ADP'),\n",
       " (u'Thursday', u'NOUN'),\n",
       " (u'morning', u'NOUN'),\n",
       " (u'.', u'.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.pos_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After calling the pos_tags property once, the words objects will carry the POS tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'PRON'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.words[0].pos_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command Line Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization\n",
    "\n",
    "Notice, if we do not pass `--lang` the language code, the detector will bem used to detect the language of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Australia posted a World Cup record total of 417 - 6 as they beat Afghanistan by 275 runs .\n",
      "David Warner hit 178 off 133 balls , Steve Smith scored 95 while Glenn Maxwell struck 88 in 39 deliveries in the Pool A encounter in Perth .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2015-03-05 17:21:22 INFO __main__.py: 246 Language English is detected while reading the first 1128 bytes.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "tok_file=/tmp/cricket.tok.txt\n",
    "polyglot tokenize --input testdata/cricket.txt > $tok_file\n",
    "head -n 2 $tok_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Australia       NOUN \n",
      "posted          VERB \n",
      "a               DET  \n",
      "World           NOUN \n",
      "Cup             NOUN \n",
      "record          NOUN \n",
      "total           NOUN \n",
      "of              ADP  \n",
      "417             NOUN \n",
      "-               .    \n",
      "6               NOUN \n",
      "as              ADP  \n",
      "they            PRON \n",
      "beat            VERB \n",
      "Afghanistan     NOUN \n",
      "by              ADP  \n",
      "275             NOUN \n",
      "runs            NOUN \n",
      ".               .    \n",
      "\n",
      "David           NOUN \n",
      "Warner          NOUN \n",
      "hit             VERB \n",
      "178             ADJ  \n",
      "off             ADP  \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "tok_file=/tmp/cricket.tok.txt\n",
    "polyglot --lang en pos --input $tok_file | head -n 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nesting steps\n",
    "We can nest the tokenization and POS tagging in a simple bash pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which           DET  \r\n",
      "India           NOUN \r\n",
      "beat            VERB \r\n",
      "Bermuda         NOUN \r\n",
      "in              ADP  \r\n",
      "Port            NOUN \r\n",
      "of              ADP  \r\n",
      "Spain           NOUN \r\n",
      "in              ADP  \r\n",
      "2007            NOUN \r\n",
      ",               .    \r\n",
      "which           DET  \r\n",
      "was             VERB \r\n",
      "equalled        VERB \r\n",
      "five            NUM  \r\n",
      "days            NOUN \r\n",
      "ago             ADV  \r\n",
      "by              ADP  \r\n",
      "South           NOUN \r\n",
      "Africa          NOUN \r\n",
      "in              ADP  \r\n",
      "their           PRON \r\n",
      "victory         NOUN \r\n",
      "over            ADP  \r\n",
      "West            NOUN \r\n",
      "Indies          NOUN \r\n",
      "in              ADP  \r\n",
      "Sydney          NOUN \r\n",
      ".               .    \r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!polyglot --lang en tokenize --input testdata/cricket.txt |  polyglot --lang en pos | tail -n 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citation\n",
    "\n",
    "This work is a direct implementation of the research being described in the [Polyglot: Distributed Word Representations for Multilingual NLP](http://www.aclweb.org/anthology/W13-3520) paper.\n",
    "The author of this library strongly encourage you to cite the following paper if you are using this software."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. code-block::\n",
    "   @InProceedings{polyglot:2013:ACL-CoNLL,\n",
    "     author    = {Al-Rfou, Rami  and  Perozzi, Bryan  and  Skiena, Steven},\n",
    "     title     = {Polyglot: Distributed Word Representations for Multilingual NLP},\n",
    "     booktitle = {Proceedings of the Seventeenth Conference on Computational Natural Language Learning},\n",
    "     month     = {August},\n",
    "     year      = {2013},\n",
    "     address   = {Sofia, Bulgaria},\n",
    "     publisher = {Association for Computational Linguistics},\n",
    "     pages     = {183--192}, \n",
    "     url       = {http://www.aclweb.org/anthology/W13-3520}\n",
    "   }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Universal Part of Speech Tagging](http://universaldependencies.github.io/docs/u/pos/index.html)\n",
    "- [Universal Dependencies 1.0](https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-1464)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
