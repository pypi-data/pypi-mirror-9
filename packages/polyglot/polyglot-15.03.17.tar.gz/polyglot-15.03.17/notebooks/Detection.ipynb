{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polyglot depends on [pycld2](https://pypi.python.org/pypi/pycld2/) library which in turn depends on [cld2](https://code.google.com/p/cld2/) library for detecting language(s) used in plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from polyglot.detect import Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arabic_text = u\"\"\"\n",
    "أفاد مصدر امني في قيادة عمليات صلاح الدين في العراق بأن \" القوات الامنية تتوقف لليوم\n",
    "الثالث على التوالي عن التقدم الى داخل مدينة تكريت بسبب\n",
    "انتشار قناصي التنظيم الذي يطلق على نفسه اسم \"الدولة الاسلامية\" والعبوات الناسفة\n",
    "والمنازل المفخخة والانتحاريين، فضلا عن ان القوات الامنية تنتظر وصول تعزيزات اضافية \".\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Arabic      code: ar       confidence:  99.0 read bytes:   907\n"
     ]
    }
   ],
   "source": [
    "detector = Detector(arabic_text)\n",
    "print(detector.language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mixed_text = u\"\"\"\n",
    "China (simplified Chinese: 中国; traditional Chinese: 中國),\n",
    "officially the People's Republic of China (PRC), is a sovereign state located in East Asia.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the text contains snippets from different languages, the detector is able to find the most probable langauges used in the text.\n",
    "For each language, we can query the model confidence level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: English     code: en       confidence:  87.0 read bytes:  1154\n",
      "name: Chinese     code: zh_Hant  confidence:   5.0 read bytes:  1755\n",
      "name: un          code: un       confidence:   0.0 read bytes:     0\n"
     ]
    }
   ],
   "source": [
    "for language in Detector(mixed_text).languages:\n",
    "  print(language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To take a closer look, we can inspect the text line by line, notice that the confidence in the detection went down for the first line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "China (simplified Chinese: 中国; traditional Chinese: 中國), \n",
      "\n",
      "name: English     code: en       confidence:  71.0 read bytes:   887\n",
      "name: Chinese     code: zh_Hant  confidence:  11.0 read bytes:  1755\n",
      "name: un          code: un       confidence:   0.0 read bytes:     0\n",
      "\n",
      "\n",
      "officially the People's Republic of China (PRC), is a sovereign state located in East Asia. \n",
      "\n",
      "name: English     code: en       confidence:  98.0 read bytes:  1291\n",
      "name: un          code: un       confidence:   0.0 read bytes:     0\n",
      "name: un          code: un       confidence:   0.0 read bytes:     0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in mixed_text.strip().splitlines():\n",
    "  print(line, \"\\n\")\n",
    "  for language in Detector(line).languages:\n",
    "    print(language)\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Effort Strategy\n",
    "\n",
    "Sometimes, there is no enough text to make a decision, like detecting a language from one word.\n",
    "This forces the detector to switch to a best effort strategy, a warning will be thrown and the attribute `reliable` will be set to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:polyglot.detect.base:Detector is not able to detect the language reliably.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is reliable: False\n",
      "Language 1: name: English     code: en       confidence:  85.0 read bytes:  1194\n",
      "Language 2: name: un          code: un       confidence:   0.0 read bytes:     0\n",
      "Language 3: name: un          code: un       confidence:   0.0 read bytes:     0\n"
     ]
    }
   ],
   "source": [
    "detector = Detector(\"pizza\")\n",
    "print(detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case, that the detection is not reliable even when we are using the best effort strategy, an exception `UnknownLanguage` will be thrown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnknownLanguage",
     "evalue": "Try passing a longer snippet of text",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownLanguage\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-de43776398b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDetector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"4\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/polyglot-15.03.12-py2.7.egg/polyglot/detect/base.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, text, quiet)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquiet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquiet\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;34m\"\"\"If true, exceptions will be silenced.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/polyglot-15.03.12-py2.7.egg/polyglot/detect/base.pyc\u001b[0m in \u001b[0;36mdetect\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mreliable\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquiet\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mUnknownLanguage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Try passing a longer snippet of text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Detector is not able to detect the language reliably.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownLanguage\u001b[0m: Try passing a longer snippet of text"
     ]
    }
   ],
   "source": [
    "print(Detector(\"4\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such an exception may not be desirable especially for trivial cases like characters that could belong to so many languages.\n",
    "In this case, we can silence the exceptions by passing setting `quiet` to `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:polyglot.detect.base:Detector is not able to detect the language reliably.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is reliable: False\n",
      "Language 1: name: un          code: un       confidence:   0.0 read bytes:     0\n",
      "Language 2: name: un          code: un       confidence:   0.0 read bytes:     0\n",
      "Language 3: name: un          code: un       confidence:   0.0 read bytes:     0\n"
     ]
    }
   ],
   "source": [
    "print(Detector(\"4\", quiet=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: polyglot detect [-h] [--input [INPUT [INPUT ...]]]\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --input [INPUT [INPUT ...]]\r\n"
     ]
    }
   ],
   "source": [
    "!polyglot detect --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subcommand `detect` tries to identify the language code for each line in a text file.\n",
    "This could be convieniet if each line represents a document or a sentence that could have been generated by a tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English             Australia posted a World Cup record total of 417-6 as they beat Afghanistan by 275 runs.\r\n",
      "English             David Warner hit 178 off 133 balls, Steve Smith scored 95 while Glenn Maxwell struck 88 in 39 deliveries in the Pool A encounter in Perth.\r\n",
      "English             Afghanistan were then dismissed for 142, with Mitchell Johnson and Mitchell Starc taking six wickets between them.\r\n",
      "English             Australia's score surpassed the 413-5 India made against Bermuda in 2007.\r\n",
      "English             It continues the pattern of bat dominating ball in this tournament as the third 400 plus score achieved in the pool stages, following South Africa's 408-5 and 411-4 against West Indies and Ireland respectively.\r\n",
      "English             The winning margin beats the 257-run amount by which India beat Bermuda in Port of Spain in 2007, which was equalled five days ago by South Africa in their victory over West Indies in Sydney.\r\n"
     ]
    }
   ],
   "source": [
    "!polyglot detect --input testdata/cricket.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supported Languages\n",
    "\n",
    "cld2 can detect up to 165 languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abkhazian; Afar; Afrikaans; Akan; Albanian; Amharic; Arabic; Armenian; Assamese; Aymara; Azerbaijani; Bashkir; Basque; Belarusian; Bengali; Bihari; Bislama; Bosnian; Breton; Bulgarian; Burmese; Catalan; Cebuano; Cherokee; Nyanja; Corsican; Croatian; Croatian; Czech; Chinese; Chinese; Chinese; Chinese; Chineset; Chineset; Chineset; Chineset; Chineset; Chineset; Danish; Dhivehi; Dutch; Dzongkha; English; Esperanto; Estonian; Ewe; Faroese; Fijian; Finnish; French; Frisian; Ga; Galician; Ganda; Georgian; German; Greek; Greenlandic; Guarani; Gujarati; Haitian_creole; Hausa; Hawaiian; Hebrew; Hebrew; Hindi; Hmong; Hungarian; Icelandic; Igbo; Indonesian; Interlingua; Interlingue; Inuktitut; Inupiak; Irish; Italian; Ignore; Javanese; Javanese; Japanese; Kannada; Kashmiri; Kazakh; Khasi; Khmer; Kinyarwanda; Krio; Kurdish; Kyrgyz; Korean; Laothian; Latin; Latvian; Limbu; Limbu; Limbu; Lingala; Lithuanian; Lozi; Luba_lulua; Luo_kenya_and_tanzania; Luxembourgish; Macedonian; Malagasy; Malay; Malayalam; Maltese; Manx; Maori; Marathi; Mauritian_creole; Romanian; Mongolian; Montenegrin; Montenegrin; Montenegrin; Montenegrin; Nauru; Ndebele; Nepali; Newari; Norwegian; Norwegian; Norwegian_n; Nyanja; Occitan; Oriya; Oromo; Ossetian; Pampanga; Pashto; Pedi; Persian; Polish; Portuguese; Punjabi; Quechua; Rajasthani; Rhaeto_romance; Romanian; Rundi; Russian; Samoan; Sango; Sanskrit; Scots; Scots_gaelic; Serbian; Serbian; Seselwa; Seselwa; Sesotho; Shona; Sindhi; Sinhalese; Siswant; Slovak; Slovenian; Somali; Spanish; Sundanese; Swahili; Swedish; Syriac; Tagalog; Tajik; Tamil; Tatar; Telugu; Thai; Tibetan; Tigrinya; Tonga; Tsonga; Tswana; Tumbuka; Turkish; Turkmen; Twi; Uighur; Ukrainian; Urdu; Uzbek; Venda; Vietnamese; Volapuk; Waray_philippines; Welsh; Wolof; Xhosa; X_arabic; X_armenian; X_avestan; X_bork_bork_bork; X_balinese; X_bamum; X_batak; X_bengali; X_bopomofo; X_brahmi; X_braille; X_buginese; X_buhid; X_canadian_aboriginal; X_carian; X_chakma; X_cham; X_cherokee; X_common; X_coptic; X_cuneiform; X_cypriot; X_cyrillic; X_deseret; X_devanagari; X_elmer_fudd; X_egyptian_hieroglyphs; X_ethiopic; X_georgian; X_glagolitic; X_gothic; X_greek; X_gujarati; X_gurmukhi; X_hacker; X_han; X_hangul; X_hanunoo; X_hebrew; X_hiragana; X_imperial_aramaic; X_inherited; X_inscriptional_pahlavi; X_inscriptional_parthian; X_javanese; X_klingon; X_kaithi; X_kannada; X_katakana; X_kayah_li; X_kharoshthi; X_khmer; X_lao; X_latin; X_lepcha; X_limbu; X_linear_b; X_lisu; X_lycian; X_lydian; X_malayalam; X_mandaic; X_meetei_mayek; X_meroitic_cursive; X_meroitic_hieroglyphs; X_miao; X_mongolian; X_myanmar; X_new_tai_lue; X_nko; X_ogham; X_ol_chiki; X_old_italic; X_old_persian; X_old_south_arabian; X_old_turkic; X_oriya; X_osmanya; X_pig_latin; X_phags_pa; X_phoenician; X_rejang; X_runic; X_samaritan; X_saurashtra; X_sharada; X_shavian; X_sinhala; X_sora_sompeng; X_sundanese; X_syloti_nagri; X_syriac; X_tagalog; X_tagbanwa; X_tai_le; X_tai_tham; X_tai_viet; X_takri; X_tamil; X_telugu; X_thaana; X_thai; X_tibetan; X_tifinagh; X_ugaritic; X_vai; X_yi; Yiddish; Yoruba; Zhuang; Zulu\n"
     ]
    }
   ],
   "source": [
    "print(\"; \".join(Detector.supported_languages()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
