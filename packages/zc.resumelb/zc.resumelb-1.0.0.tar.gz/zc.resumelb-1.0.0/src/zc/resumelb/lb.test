Basic LB tests
==============

The LB algorithm is tested in pool.test.  This file aims to test the
networking aspects of the LB.

An lb takes a set of worker addresses, which it connects to.  It
listens on an address for incoming web requests.  You can update its
set of worker addresses at any time.

To test lb behavior, we'll create faux workers the lb can connect to.

    >>> workers = [Worker() for i in range(2)]

We have some workers running. Now, let's create a load balancer:

    >>> import zc.resumelb.lb
    >>> lb = zc.resumelb.lb.LB([w.addr for w in workers],
    ...                        zc.resumelb.lb.host_classifier, variance=4)

Note that the lb provides an interface for changing pool
settings. This is just a link to the pool's update_settings method:

    >>> lb.update_settings == lb.pool.update_settings
    True

We pass the constructor an iterable of addresses.  The lb will connect
to these addresses. Let's wait for it to do so:

    >>> wait(
    ...     lambda :
    ...     len([w for w in workers if hasattr(w, 'socket')]) == len(workers)
    ...     )

When the workers get connections, they send the lb their resumes:

    >>> worker1, worker2 = [w.socket for w in workers]
    >>> from zc.resumelb.util import write_message

    >>> write_message(worker1, 0, {'h1.com': 10.0})
    >>> write_message(worker2, 0, {'h2.com': 10.0})

    >>> import gevent
    >>> gevent.sleep(.01) # Give resumes time to arrive

Now, let's make a request and make sure the data gets where it's
supposed to go.

    >>> import webtest
    >>> app1 = webtest.TestApp(lb.handle_wsgi)
    >>> g1 = spawn(app1.get, '/hi.html', {}, [('Host', 'h1.com')])

    >>> import zc.resumelb.util
    >>> def read_message(sock): # filter out keep alives
    ...     while 1:            # we'll look at them later
    ...         rno, data = zc.resumelb.util.read_message(sock)
    ...         if rno != 0 or data is not None:
    ...             return rno, data
    >>> rno, env1 = read_message(worker1)

    >>> rno
    1
    >>> from pprint import pprint
    >>> pprint(env1)
    {'HTTP_HOST': 'h1.com',
     'PATH_INFO': '/hi.html',
     'QUERY_STRING': '',
     'REQUEST_METHOD': 'GET',
     'SCRIPT_NAME': '',
     'SERVER_NAME': 'localhost',
     'SERVER_PORT': '80',
     'SERVER_PROTOCOL': 'HTTP/1.0',
     u'paste.testing': True,
     u'paste.testing_variables': {},
     u'paste.throw_errors': True,
     'wsgi.multiprocess': False,
     'wsgi.multithread': False,
     'wsgi.run_once': False,
     'wsgi.url_scheme': 'http',
     'wsgi.version': (1, 0),
     'zc.resumelb.request_class': 'h1.com'}

Because this is a get, the body is empty:

    >>> read_message(worker1)
    (1, '')

If we send another request for the same host, it will appear on the same
socket.  This time, we'll make a request that provides a large body:

    >>> app2 = webtest.TestApp(lb.handle_wsgi)
    >>> g2 = spawn(
    ...     app2.put, '/hi.html', 'i'*200000, [('Host', 'h1.com')])

    >>> rno, env2 = read_message(worker1)

    >>> rno
    2
    >>> pprint(env2)
    {'CONTENT_LENGTH': '200000',
     u'CONTENT_TYPE': 'application/x-www-form-urlencoded',
     'HTTP_HOST': 'h1.com',
     'PATH_INFO': '/hi.html',
     'QUERY_STRING': '',
     'REQUEST_METHOD': 'PUT',
     'SCRIPT_NAME': '',
     'SERVER_NAME': 'localhost',
     'SERVER_PORT': '80',
     'SERVER_PROTOCOL': 'HTTP/1.0',
     u'paste.testing': True,
     u'paste.testing_variables': {},
     u'paste.throw_errors': True,
     'wsgi.multiprocess': False,
     'wsgi.multithread': False,
     'wsgi.run_once': False,
     'wsgi.url_scheme': 'http',
     'wsgi.version': (1, 0),
     'zc.resumelb.request_class': 'h1.com'}

    >>> rno, data = read_message(worker1)
    >>> rno, len(data), data == 'i'*len(data)
    (2, 65536, True)

    >>> rno, data = read_message(worker1)
    >>> rno, len(data), data == 'i'*len(data)
    (2, 65536, True)

    >>> rno, data = read_message(worker1)
    >>> rno, len(data), data == 'i'*len(data)
    (2, 65536, True)

    >>> rno, data = read_message(worker1)
    >>> rno, len(data), data == 'i'*len(data)
    (2, 3392, True)

    >>> read_message(worker1)
    (2, '')


If we make a request to h2.com, we'll get the request on worker2:

    >>> app3 = webtest.TestApp(lb.handle_wsgi)
    >>> g3 = spawn(app3.get, '/hi.html', {}, [('Host', 'h2.com')])

    >>> rno, env3 = read_message(worker2)
    >>> rno
    1
    >>> pprint(env3)
    {'HTTP_HOST': 'h2.com',
     'PATH_INFO': '/hi.html',
     'QUERY_STRING': '',
     'REQUEST_METHOD': 'GET',
     'SCRIPT_NAME': '',
     'SERVER_NAME': 'localhost',
     'SERVER_PORT': '80',
     'SERVER_PROTOCOL': 'HTTP/1.0',
     u'paste.testing': True,
     u'paste.testing_variables': {},
     u'paste.throw_errors': True,
     'wsgi.multiprocess': False,
     'wsgi.multithread': False,
     'wsgi.run_once': False,
     'wsgi.url_scheme': 'http',
     'wsgi.version': (1, 0),
     'zc.resumelb.request_class': 'h2.com'}

    >>> read_message(worker2)
    (1, '')

Now, let's start sending back some data

    >>> import webob
    >>> response = webob.Response('Hello world\n')
    >>> write_message(worker2, 1, (response.status, response.headers.items()))
    >>> write_message(worker2, 1, response.body)
    >>> write_message(worker2, 1, '')
    >>> g3.join(1.0)
    >>> g3.value
    <200 OK text/html body='Hello world\n'>

We'll interleave data for the 2 responses on worker1

    >>> response1 = webob.Response('1'*10000)
    >>> write_message(worker1, 1, (response1.status, response1.headers.items()))
    >>> response2 = webob.Response('2'*10000)
    >>> write_message(worker1, 2, (response2.status, response2.headers.items()))

    >>> for i in range(10):
    ...     write_message(worker1, 1, '1'*1000)
    ...     write_message(worker1, 2, '2'*1000)

    >>> write_message(worker1, 1, '')
    >>> write_message(worker1, 2, '')

    >>> g1.join(1.0)
    >>> g1.value.status, g1.value.body == '1'*10000
    ('200 OK', True)

    >>> g2.join(1.0)
    >>> g2.value.status, g2.value.body == '2'*10000
    ('200 OK', True)

Keep-alive messages
===================

Periodically, the lb sends keep-alive messages to workers:

    >>> gevent.sleep(.15)
    >>> zc.resumelb.util.read_message(worker1)
    (0, None)

Workers ignore these.

Disconnecting clients
=====================

Sometimes, a client will disconnect after a request starts, but before
the worker has sent the result.  When this happens, the lb will get a
message from a worker for a request number that isn't active.  We'll
emulate this by sending a message with a bogus message #, and verify
that nothing is broken:

    >>> write_message(worker2, 99, '')
    >>> gevent.sleep(.01)

Pool Management
===============

At this point, there are no outstanding requests.  The pool back-logs
should all be 0:

    >>> sum(worker.backlog for worker in lb.pool.workers)
    0

Worker reprs
============

Workers use their addresses as their reprs.

    >>> print lb.pool # doctest: +ELLIPSIS
    Request classes:
      h1.com: 127.0.0.1:0(10.0,0.970...)
      h2.com: 127.0.0.1:0(10.0,0.485...)
    Backlogs:
      overall backlog: 0 Decayed: 1.47809138734 Avg: 0.73904569367
      0: [127.0.0.1:0, 127.0.0.1:0]

Worker oldest-request start times
=================================

For monitoring purposes, we want to know about requests that take a
very long time.  Load-balancer worker objects keep track of
outstanding requests.  We can query this information:

    >>> for worker in sorted(lb.pool.workers):
    ...     print worker, worker.oldest_time
    127.0.0.1:0 None
    127.0.0.1:0 None

    >>> import time
    >>> t1 = time.time()
    >>> app1 = webtest.TestApp(lb.handle_wsgi)
    >>> g1 = spawn(app1.get, '/hi.html', {}, [('Host', 'h1.com')])
    >>> rno = read_message(worker1)[0]
    >>> read_message(worker1) == (rno, '')
    True

    >>> t2 = time.time()
    >>> [ot] = [w.oldest_time for (_, w) in lb.pool.skilled['h1.com']]
    >>> t1 <= ot <= t2
    True

    >>> gevent.sleep(.01)
    >>> app2 = webtest.TestApp(lb.handle_wsgi)
    >>> g2 = spawn(app1.get, '/hi.html', {}, [('Host', 'h1.com')])
    >>> gevent.sleep(.01)
    >>> [ot] == [w.oldest_time for (_, w) in lb.pool.skilled['h1.com']]
    True

    >>> response = webob.Response('Hello world\n')
    >>> write_message(worker1, rno, (response.status, response.headers.items()))
    >>> write_message(worker1, rno, response.body)
    >>> write_message(worker1, rno, '')
    >>> g1.join(1.0)
    >>> [ot2] = [w.oldest_time for (_, w) in lb.pool.skilled['h1.com']]
    >>> ot2 > ot
    True

    >>> rno = read_message(worker1)[0]
    >>> read_message(worker1) == (rno, '')
    True
    >>> response = webob.Response('Hello world\n')
    >>> write_message(worker1, rno, (response.status, response.headers.items()))
    >>> write_message(worker1, rno, response.body)
    >>> write_message(worker1, rno, '')
    >>> g2.join(1.0)

    >>> for worker in sorted(lb.pool.workers):
    ...     print worker, worker.oldest_time
    127.0.0.1:0 None
    127.0.0.1:0 None


Worker disconnection
====================

When a worker disconnects from a running lb, any pending GET or HEAD
requests are resubmitted to another worker. All other requests
generate a 500 response.

Also, if a worker has already sent part of the response and
disconnects, that response is simply truncated.

    >>> greenlets = []
    >>> for method in ('GET', 'GET', 'HEAD', 'PUT', 'POST', 'DELETE',
    ...                'OPTIONS', 'TRACE'):
    ...     app = webtest.TestApp(lb.handle_wsgi)
    ...     greenlets.append(
    ...         spawn(app.request, '/hi.html', method=method,
    ...                      headers=[('Host', 'h1.com')], status='*'))
    ...     rno, data = read_message(worker1)
    ...     rno2, blank = read_message(worker1)
    ...     if rno2 != rno or blank != '':
    ...         print 'oops', (rno2, blank)
    ...     print rno, type(data)
    5 <type 'dict'>
    6 <type 'dict'>
    7 <type 'dict'>
    8 <type 'dict'>
    9 <type 'dict'>
    10 <type 'dict'>
    11 <type 'dict'>
    12 <type 'dict'>

Now, let's send a partial response from the first GET:

    >>> write_message(worker1, 5, ('200 OK', [
    ...   ('Content-Length', '42'), ('Content-Type', 'text/html')]))
    >>> gevent.sleep(.01)

Now, we'll disconnect worker1:

    >>> workers[0].close()
    >>> gevent.sleep(.1)

The second GET and the HEAD request will be send to worker2:

    >>> rno1, env1 = read_message(worker2)
    >>> rno, blank = read_message(worker2)
    ... if rno != rno1 or blank != '':
    ...     print 'oops', (rno, blank)

    >>> rno2, env2 = read_message(worker2)
    >>> rno, blank = read_message(worker2)
    ... if rno != rno2 or blank != '':
    ...     print 'oops', (rno, blank)

    >>> sorted((env1['REQUEST_METHOD'], env2['REQUEST_METHOD']))
    ['GET', 'HEAD']

    >>> response = webob.Response('Hello test\n')
    >>> for (rno, env) in ((rno1, env1), (rno2, env2)):
    ...     write_message(worker2, rno,
    ...                   (response.status, response.headers.items()))
    ...     if env['REQUEST_METHOD'] == 'GET':
    ...         write_message(worker2, rno, response.body)
    ...     write_message(worker2, rno, '')

    >>> for g in greenlets:
    ...    g.join(1.0)
    ...    print repr(g.value)
    <200 OK text/html no body>
    <200 OK text/html body='Hello test\n'>
    <200 OK text/html no body>
    <502 Bad Gateway text/html body='\n<html><...l>\n'/159>
    <502 Bad Gateway text/html body='\n<html><...l>\n'/159>
    <502 Bad Gateway text/html body='\n<html><...l>\n'/159>
    <502 Bad Gateway text/html body='\n<html><...l>\n'/159>
    <502 Bad Gateway text/html body='\n<html><...l>\n'/159>

    >>> print greenlets[3].value.body
    <BLANKLINE>
    <html><meta http-equiv="refresh" content="1"><body>
    The server was unable to handle your request due to a transient failure.
    Please try again.
    </body></html>
    <BLANKLINE>

Note that at this point, there shouldn't be any in-flight requests and
the backlog should be 0:

    >>> lb.pool.backlog
    0

Automatic reconnection
======================

Meanwhile, since worker1 disconnected, the load balancer reconnected
to the same address. We can see this because the first worker (server)
has a new socket:

    >>> workers[0].socket != worker1
    True

It's not in the lb pool yet, because we haven't sent its resume yet:

    >>> len(lb.pool.workers)
    1

But if we send a resume, it will be:

    >>> write_message(workers[0].socket, 0, {'h3.com': 10.0})
    >>> gevent.sleep(.01)
    >>> len(lb.pool.workers)
    2

In the test above, the worker was still listening the whole time.
Let's go a bit further.  We'll shut down the worker's server as well
as the worker socket. When the lb gets an error, it sleeps a a second
after failed attempts.  We can change this by setting a class variable
that exists primarily for testing.  We'll change it on the lb.

    >>> lb.connect_sleep = 0.01
    >>> port = workers[0].server.server_port # We'll reuse below
    >>> workers[0].server.stop()
    >>> socket = workers[0].close()
    >>> gevent.sleep(.01)
    >>> len(lb.pool.workers)
    1

OK, so we lost the worker and the lb didn't reconnect because the
worker server is down:

    >>> hasattr(workers[0], 'socket')
    False

Now, we'll recreate the worker server and after a bit, the lb should reconnect:

    >>> workers[0].server = gevent.server.StreamServer(
    ...     ('127.0.0.1', port), workers[0].handle)
    >>> workers[0].server.start()
    >>> wait(lambda : hasattr(workers[0], 'socket'))
    >>> write_message(workers[0].socket, 0, {'h3.com': 10.0})
    >>> gevent.sleep(.01)
    >>> len(lb.pool.workers)
    2


Adding and removing workers
===========================

We can add and remove workers by passing new address iterables to the
lb set_worker_addrs method.

Let's add a worker and wait for it to be connected:

    >>> workers.append(Worker())
    >>> lb.set_worker_addrs([w.addr for w in workers])
    >>> wait(lambda : hasattr(workers[-1], 'socket'))
    >>> write_message(workers[-1].socket, 0, {'h4.com': 10})
    >>> gevent.sleep(.01)
    >>> len(lb.pool.workers)
    3

If we submit an h4.com request, it will go to the new worker:

    >>> g = spawn(app1.get, '/hi.html', {}, [('Host', 'h4.com')])
    >>> rno, env = read_message(workers[-1].socket)
    >>> read_message(workers[-1].socket)
    (1, '')

Now, let's remove a worker:

    >>> out = workers.pop(0)
    >>> lb.set_worker_addrs([w.addr for w in workers])

Removing a worker doesn't disconnect it, but it will prevent it from
being reconnected if it disconnects on its own.

    >>> gevent.sleep(.01)
    >>> len(lb.pool.workers)
    3

    >>> outsocket = out.socket
    >>> outsocket.close()
    >>> gevent.sleep(.01)
    >>> len(lb.pool.workers)
    2

Because the lb didn't reconnect, our socket is still the one from
before that we closed:

    >>> out.socket is outsocket
    True

Typically, by the time we remove an address, the worker will already
have gone away.

By default, workers don't have versions:

    >>> [w.version for w in lb.pool.workers]
    [None, None]

When adding workers, however, we can supply a dictionary, mapping
addresses to versions, rather than a list.

    >>> workers.append(Worker())
    >>> lb.set_worker_addrs(dict((w.addr, 1) for w in workers))
    >>> wait(lambda : hasattr(workers[-1], 'socket'))
    >>> write_message(workers[-1].socket, 0, {'h4.com': 10})
    >>> gevent.sleep(.01)
    >>> sorted(str(w.version) for w in lb.pool.workers)
    ['1', 'None', 'None']

(only new workers are affected.)

    >>> workers.pop(-1).close()
    >>> lb.set_worker_addrs([w.addr for w in workers])

Graceful shutdown
=================

Load balancers have a shutdown method that:

- stops accepting web connections
- Waits for requests to be worked off
- disconnects from workers

We already have a request in flight.  Let's add another on a different
worker:

    >>> g2 = spawn(app2.get, '/hi.html', {}, [('Host', 'h2.com')])

    >>> gevent.sleep(.01)
    >>> [w.backlog for w in lb.pool.workers]
    [1, 1]

If we call shutdown, it will block until we have no in-flight
connections, so we'll call it in a greenlet:

    >>> shutdown_greenlet = spawn(lb.shutdown)
    >>> gevent.sleep(.01)
    >>> shutdown_greenlet.ready()
    False

Now, let's finish the outstanding requests:

    >>> write_message(workers[-1].socket, rno,
    ...      (response.status, response.headers.items()))
    >>> write_message(workers[-1].socket, rno, response.body)
    >>> write_message(workers[-1].socket, rno, '')
    >>> g.join(1.0)

    >>> rno, env = read_message(workers[0].socket)
    >>> read_message(workers[0].socket)
    (4, '')

    >>> write_message(workers[0].socket, rno,
    ...      (response.status, response.headers.items()))
    >>> write_message(workers[0].socket, rno, response.body)
    >>> write_message(workers[0].socket, rno, '')
    >>> g2.join(1.0)

    >>> gevent.sleep(.01)
    >>> shutdown_greenlet.ready()
    True

At this point, the worker sockets are closed. If we read from them,
we'll get an empty string (or a keep-alive message, which we'll
ignore):

    >>> import zc.resumelb.util
    >>> def at_end(sock):
    ...     while 1:
    ...         data = sock.recv(9)
    ...         if data == zc.resumelb.util.KEEP_ALIVE:
    ...             continue
    ...         if data:
    ...             print 'unexpected data', repr(data)
    ...         else:
    ...             break
    >>> for w in workers:
    ...     at_end(w.socket)

Built-in request classifiers
============================

The zc.resume.lb module has a host-based request classifier:

    >>> zc.resumelb.lb.host_classifier(dict(HTTP_HOST='example.com'))
    'example.com'

    >>> zc.resumelb.lb.host_classifier(dict(HTTP_HOST='www.example.com'))
    'example.com'

A more general classifier is the re_classifier.  It is a classifier
factory that takes a environment name and a regular expression.  The
regular expression must define a group named 'class':

    >>> classifier = zc.resumelb.lb.re_classifier(
    ...    'PATH_INFO', r'^/(?P<class>[^/]*)')
    >>> classifier(dict(PATH_INFO=''))
    ''
    >>> classifier({})
    ''
    >>> classifier(dict(PATH_INFO='/'))
    ''
    >>> classifier(dict(PATH_INFO='/foo'))
    'foo'
    >>> classifier(dict(PATH_INFO='/foo/bar/baz'))
    'foo'
